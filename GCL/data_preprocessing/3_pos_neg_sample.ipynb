{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2f13e35-4125-43a0-ad49-99b0e4386336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Optimized\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import sys\n",
    "#base_dir = os.environ['AWEB_DIR']\n",
    "sys.path.append(\"../../\")\n",
    "import config\n",
    "# Approach1: top and bottom similar for each weak and attack\n",
    "# anchor nodes: 1136\n",
    "# postive nodes: 668\n",
    "# negative nodes : 490\n",
    "\n",
    "# Sample 2 pt_gpt: using thresold pos=0.65, neg=0.45 select anchors that present both in positive and negative.\n",
    "# pos pair 82554\n",
    "# neg pair 30772\n",
    "# anchor nodes: 893\n",
    "# postive nodes: 536\n",
    "# negative nodes : 212\n",
    "\n",
    "# Sample 2 ft_gpt: using thresold pos=0.45, neg=0.30 select anchors that present both in positive and negative.\n",
    "# pos pair 70878\n",
    "# neg pair 55820\n",
    "# anchor nodes: 1034\n",
    "# postive nodes: 765\n",
    "# negative nodes : 618"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6391ea32-3b7d-4f8e-b2ef-f46a73d0b017",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"pt_SecRoBERTa\",\"SecRoBERTa\",\"pt_SecureBERT\",\"SecureBERT\",\"pt_gpt2-xl\",\"gpt2-xl\"]\n",
    "result_dir = config.OUTPUT_DIR\n",
    "embeddings_dir = config.EMBEDDING_DIR\n",
    "data_dir = config.DATA_DIR\n",
    "model_name = models[4]\n",
    "cwe_per_attack = 30\n",
    "attack_per_cwe = 50\n",
    "positive_threshold = 0.65\n",
    "negative_threshold = 0.45\n",
    "text_emb_dir = embeddings_dir+model_name+\"/\"\n",
    "output_dir = result_dir+\"gcl_data/\"+model_name+\"/\"\n",
    "# Assuming predefined weights are stored in a numpy array named 'predefined_embeddings1_weights'\n",
    "text_embeddings = np.load(text_emb_dir+'text_embeddings.npy')\n",
    "hop_text_embeddings = np.load(text_emb_dir+'text_hop_embeddings.npy')\n",
    "with open(data_dir+\"doc_id_to_emb_id.json\") as f:\n",
    "    doc_id_to_emb_id = json.load(f)\n",
    "with open(data_dir+\"emb_id_to_doc_id.json\") as f:\n",
    "    emb_id_to_doc_id = json.load(f)\n",
    "with open(data_dir+'attack_weak_range.json') as fp:\n",
    "    attack_weak_range = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dc84875-cf39-42b0-abb7-816ccb7df989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Placeholder function for generating text embeddings\n",
    "# def get_text_embeddings(text_embeddings, nodes):\n",
    "#     return [text_embeddings[node] for node in nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20dcf661-51f8-412f-8905-08f083e352ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_range = attack_weak_range['attack']\n",
    "weak_range = attack_weak_range['cwe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36ec9681-81a1-4ac2-8d5b-957669cf263b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attack': [0, 2043], 'cwe': [2043, 2982], 'n_nodes': 2982}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attack_weak_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2129d2a5-001a-44ba-8d1b-0173be042b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for both sets of nodes\n",
    "attack_nodes = list(range(attack_range[0],attack_range[1]))\n",
    "weakness_nodes = list(range(weak_range[0],weak_range[1]))\n",
    "attack_embeddings = text_embeddings[attack_nodes]\n",
    "weakness_embeddings = text_embeddings[weakness_nodes]\n",
    "hop_attack_embeddings = hop_text_embeddings[attack_nodes]\n",
    "hop_weakness_embeddings = hop_text_embeddings[weakness_nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e137ad65-e7b4-46f4-8291-50dded01d015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity between all pairs of nodes\n",
    "weak_attack_matrix = cosine_similarity(weakness_embeddings, attack_embeddings)\n",
    "# Compute cosine similarity between all pairs of nodes\n",
    "attack_weak_matrix = cosine_similarity(attack_embeddings, weakness_embeddings)\n",
    "\n",
    "# Compute cosine similarity between all pairs of nodes\n",
    "hop_attack_matrix = cosine_similarity(hop_attack_embeddings, hop_attack_embeddings)\n",
    "# Compute cosine similarity between all pairs of nodes\n",
    "hop_weak_matrix = cosine_similarity(hop_weakness_embeddings, hop_weakness_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8275a1fb-9a99-44d2-89ea-1fafc7cd1f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach1: using top and bottom similar for each weak and attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28de2277-11ab-4905-9bf4-17974f24c787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_1():\n",
    "    anchor_pos_neg_triple = []\n",
    "    for i, attack_node in enumerate(attack_nodes):\n",
    "        # Get the similarity scores for the current attack node\n",
    "        sim_scores = attack_weak_matrix[i]\n",
    "        \n",
    "        # Get the indices of the 5 most similar and 5 least similar nodes\n",
    "        top5_sim_indices = np.argsort(sim_scores)[-cwe_per_attack:]  # Most similar\n",
    "        bottom5_sim_indices = np.argsort(sim_scores)[:cwe_per_attack]  # Least similar\n",
    "        \n",
    "        # Select the most similar positive nodes\n",
    "        # Select the least similar negative nodes\n",
    "        for j in range(len(top5_sim_indices)):\n",
    "            idx1 = top5_sim_indices[j]\n",
    "            idx2 = bottom5_sim_indices[j]\n",
    "            anchor_pos_neg_triple.append((attack_node, weakness_nodes[idx1], weakness_nodes[idx2]))\n",
    "    for i, weak_node in enumerate(weakness_nodes):\n",
    "        # Get the similarity scores for the current attack node\n",
    "        sim_scores = weak_attack_matrix[i]\n",
    "        \n",
    "        # Get the indices of the 5 most similar and 5 least similar nodes\n",
    "        top5_sim_indices = np.argsort(sim_scores)[-attack_per_cwe:]  # Most similar\n",
    "        bottom5_sim_indices = np.argsort(sim_scores)[:attack_per_cwe]  # Least similar\n",
    "        \n",
    "        # Select the most similar positive nodes\n",
    "        # Select the least similar negative nodes\n",
    "        for j in range(len(top5_sim_indices)):\n",
    "            idx1 = top5_sim_indices[j]\n",
    "            idx2 = bottom5_sim_indices[j]\n",
    "            anchor_pos_neg_triple.append((weak_node, attack_nodes[idx1], attack_nodes[idx2]))\n",
    "    anchor_set = set()\n",
    "    positive_set=set()\n",
    "    negative_set=set()\n",
    "    for a,p,n in anchor_pos_neg_triple:\n",
    "        anchor_set.add(a)\n",
    "        positive_set.add(p)\n",
    "        negative_set.add(n)\n",
    "        if(a>=weak_range[1] or p>=weak_range[1] or n>=weak_range[1]):\n",
    "            print(a,\" \",p,\" \", n)\n",
    "    print(\"# anchor nodes:\",len(anchor_set))\n",
    "    print(\"# postive nodes:\",len(positive_set))\n",
    "    print(\"# negative nodes :\",len(negative_set))\n",
    "    print(\"# examples: \", len(anchor_pos_neg_triple))\n",
    "    with open(output_dir+'anchor_pos_neg_triple_1.pkl', 'wb') as f:\n",
    "        pickle.dump(anchor_pos_neg_triple, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5bbc0e-a929-493a-a736-0f618d7c0d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_2():\n",
    "    anchor_pos_pair2 = []\n",
    "    anchor_neg_pair2 = []\n",
    "    \n",
    "    # Find anchor-positive and anchor-negative pairs based on thresholds\n",
    "    weakness_idxs, attack_idxs = np.where(attack_weak_matrix >= positive_threshold)\n",
    "    anchor_pos_pair2.extend([(attack_nodes[i], weakness_nodes[j], attack_weak_matrix[i, j]) for i, j in zip(weakness_idxs, attack_idxs)])\n",
    "    \n",
    "    weakness_idxs, attack_idxs = np.where(attack_weak_matrix <= negative_threshold)\n",
    "    anchor_neg_pair2.extend([(attack_nodes[i], weakness_nodes[j], attack_weak_matrix[i, j]) for i, j in zip(weakness_idxs, attack_idxs)])\n",
    "    \n",
    "    attack_idxs, weakness_idxs = np.where(weak_attack_matrix >= positive_threshold)\n",
    "    anchor_pos_pair2.extend([(weakness_nodes[i], attack_nodes[j], weak_attack_matrix[i, j]) for i, j in zip(attack_idxs, weakness_idxs)])\n",
    "    \n",
    "    attack_idxs, weakness_idxs = np.where(weak_attack_matrix <= negative_threshold)\n",
    "    anchor_neg_pair2.extend([(weakness_nodes[i], attack_nodes[j], weak_attack_matrix[i, j]) for i, j in zip(attack_idxs, weakness_idxs)])\n",
    "    \n",
    "    #Sort pairs\n",
    "    anchor_pos_pair2.sort(reverse=True, key=lambda x: x[2])\n",
    "    anchor_neg_pair2.sort(key=lambda x: x[2])\n",
    "    \n",
    "    print(len(anchor_pos_pair2))\n",
    "    print(len(anchor_neg_pair2))\n",
    "    \n",
    "    # Make triplets (anchor, positive, negative)\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    anchor_pos_neg_triple = []\n",
    "    anchor_neg_dict = defaultdict(list)\n",
    "    \n",
    "    for anchor, neg, val in anchor_neg_pair2:\n",
    "        anchor_neg_dict[anchor].append((neg, val))\n",
    "    \n",
    "    for anchor, pos, pos_val in anchor_pos_pair2:\n",
    "        if anchor in anchor_neg_dict and anchor_neg_dict[anchor]:\n",
    "            neg, neg_val = anchor_neg_dict[anchor].pop(0)\n",
    "            anchor_pos_neg_triple.append((anchor, pos, neg))\n",
    "    anchor_set = set()\n",
    "    positive_set=set()\n",
    "    negative_set=set()\n",
    "    for a,p,n in anchor_pos_neg_triple:\n",
    "        anchor_set.add(a)\n",
    "        positive_set.add(p)\n",
    "        negative_set.add(n)\n",
    "        if(a>=weak_range[1] or p>=weak_range[1] or n>=weak_range[1]):\n",
    "            print(a,\" \",p,\" \", n)\n",
    "    print(\"# anchor nodes:\",len(anchor_set))\n",
    "    print(\"# postive nodes:\",len(positive_set))\n",
    "    print(\"# negative nodes :\",len(negative_set))\n",
    "    print(\"# Sample:\",len(anchor_pos_neg_triple))\n",
    "    \n",
    "    th_path= output_dir+\"{}_{}/\".format(positive_threshold, negative_threshold)\n",
    "    if not os.path.exists(th_path):\n",
    "        os.makedirs(th_path)\n",
    "    with open(th_path+'anchor_pos_neg_triple_2.pkl', 'wb') as f:\n",
    "        pickle.dump(anchor_pos_neg_triple, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cd0ff2-2219-4b69-a15a-9a3f5369d6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_3():\n",
    "    anchor_pos_neg_triple = []\n",
    "    for i, attack_node in enumerate(attack_nodes):\n",
    "        # Get the similarity scores for the current attack node\n",
    "        sim_scores = attack_weak_matrix[i]\n",
    "        sim_scores2 = hop_attack_matrix[i]\n",
    "        # Get the indices of the 5 most similar and 5 least similar nodes\n",
    "        top5_sim_indices = np.argsort(sim_scores)[-cwe_per_attack:]  # Most similar\n",
    "        bottom5_sim_indices = np.argsort(sim_scores2)[:cwe_per_attack]  # Least similar\n",
    "        \n",
    "        # Select the most similar positive nodes\n",
    "        # Select the least similar negative nodes\n",
    "        for j in range(len(top5_sim_indices)):\n",
    "            idx1 = top5_sim_indices[j]\n",
    "            idx2 = bottom5_sim_indices[j]\n",
    "            anchor_pos_neg_triple.append((attack_node, weakness_nodes[idx1], attack_nodes[idx2]))\n",
    "    for i, weak_node in enumerate(weakness_nodes):\n",
    "        # Get the similarity scores for the current attack node\n",
    "        sim_scores = weak_attack_matrix[i]\n",
    "        sim_scores2 = hop_weak_matrix[i]\n",
    "        # Get the indices of the 5 most similar and 5 least similar nodes\n",
    "        top5_sim_indices = np.argsort(sim_scores)[-attack_per_cwe:]  # Most similar\n",
    "        bottom5_sim_indices = np.argsort(sim_scores2)[:attack_per_cwe]  # Least similar\n",
    "        \n",
    "        # Select the most similar positive nodes\n",
    "        # Select the least similar negative nodes\n",
    "        for j in range(len(top5_sim_indices)):\n",
    "            idx1 = top5_sim_indices[j]\n",
    "            idx2 = bottom5_sim_indices[j]\n",
    "            anchor_pos_neg_triple.append((weak_node, attack_nodes[idx1], weakness_nodes[idx2]))\n",
    "    anchor_set = set()\n",
    "    positive_set=set()\n",
    "    negative_set=set()\n",
    "    for a,p,n in anchor_pos_neg_triple:\n",
    "        anchor_set.add(a)\n",
    "        positive_set.add(p)\n",
    "        negative_set.add(n)\n",
    "        if(a>=weak_range[1] or p>=weak_range[1] or n>=weak_range[1]):\n",
    "            print(a,\" \",p,\" \", n)\n",
    "    print(\"# anchor nodes:\",len(anchor_set))\n",
    "    print(\"# postive nodes:\",len(positive_set))\n",
    "    print(\"# negative nodes :\",len(negative_set))\n",
    "    print(\"# examples: \", len(anchor_pos_neg_triple))\n",
    "    with open(output_dir+'anchor_pos_neg_triple_3.pkl', 'wb') as f:\n",
    "        pickle.dump(anchor_pos_neg_triple, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c920c8b1-9427-4bbc-b2cb-5458280ad668",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sample_1()\n",
    "get_sample_2()\n",
    "get_sample_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0be9afc6-556f-4308-8412-31701c847c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach3: positive from attack-weak, negative from attack-attack, weak-weak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a28c15dc-ed3a-4e84-aaa7-e6dd0c62834c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b63294c9-7384-4e24-a99c-d9a526326850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fd10f83-f3fd-47fb-8834-8f5c19ec6c8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fec39a83-f0ca-40d0-bf61-717557138822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach2: using thresold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79c74261-63ee-48fd-bb2c-28ca567a1fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a87b6b8e-d8d7-46d4-93b9-d4d16764c256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# from collections import defaultdict\n",
    "# anchor_pos_pair = []\n",
    "# anchor_neg_pair = []\n",
    "# positive_threshold = 0.70\n",
    "# negative_threshold = 0.40\n",
    "# # There are two group of nodes.\n",
    "# # The first 2043 nodes are attack node and the embeddings = (2043, 1600) \n",
    "# # The second set 939 nodes are weakness node and the embedding shape = (939, 1600)\n",
    "# # attack_embeddings.shape = (2043, 1600)\n",
    "# # weakness_embeddings.shape = (939, 1600)\n",
    "\n",
    "# # Compute cosine similarity between weakness and attack nodes\n",
    "# # I calculate weak_attack_matrix a cosine similarity of shape (939,2043) where rows are weakness and columns are attack and values are cosine similarity\n",
    "# weak_attack_matrix = cosine_similarity(weakness_embeddings, attack_embeddings)\n",
    "# # Compute cosine similarity between attack and weakness nodes\n",
    "# # Then I calculate attack_weak_matrix a cosine similarity of shape (2043,939) where rows are attack and columns are weakness and values are cosine similarity\n",
    "# attack_weak_matrix = cosine_similarity(attack_embeddings, weakness_embeddings)\n",
    "# # This loop find the anchor-positive pairs based on positive_threshold and anchor-negative pairs based on negative_threshold from the attack_weak_matrix \n",
    "# for i, attack_node in enumerate(attack_nodes):\n",
    "#     for j, weakness_node in enumerate(weakness_nodes):\n",
    "#         if attack_weak_matrix[i, j] >= positive_threshold:\n",
    "#             anchor_pos_pair.append((attack_node,weakness_node, attack_weak_matrix[i, j]))\n",
    "#         if attack_weak_matrix[i, j] <= negative_threshold:\n",
    "#             anchor_neg_pair.append((attack_node,weakness_node, attack_weak_matrix[i, j]))\n",
    "\n",
    "# # This loop find the anchor-positive pairs based on positive_threshold and anchor-negative pairs based on negative_threshold from the weak_attack_matrix         \n",
    "# for i, weakness_node in enumerate(weakness_nodes):\n",
    "#     for j, attack_node in enumerate(attack_nodes):\n",
    "#         if weak_attack_matrix[i, j] >= positive_threshold:\n",
    "#             anchor_pos_pair.append((weakness_node,attack_node, weak_attack_matrix[i, j]))\n",
    "#         if weak_attack_matrix[i, j] <= negative_threshold:\n",
    "#             anchor_neg_pair.append((weakness_node,attack_node, weak_attack_matrix[i, j]))\n",
    "# # Now I sort the positive pairs in descending order and negative pairs in ascending order\n",
    "# anchor_pos_pair.sort(reverse=True, key=lambda x:x[2])\n",
    "# anchor_neg_pair.sort(key=lambda x:x[2])\n",
    "# print(len(anchor_pos_pair))\n",
    "# print(len(anchor_neg_pair))\n",
    "\n",
    "# Now the main purpose of the code is to make triplet (anchor,positive,negative) from the positive and negative pairs in a way that\n",
    "# For each anchor we choose the highest similar positive node and for the (anchor,positive) pair choose the lowest similar (dissimilar) negative node from (anchor,negative) pairs.\n",
    "# Once i choose a (anchor,positive,negative), i don't want to repeat the negative node for same anchor, so I remove those negative for the next (anchor,positive) pair\n",
    "# This part of the code is taking so much time due to the pop action.\n",
    "\n",
    "# anchor_pos_neg_triple = []\n",
    "# anchor_for_neg = [pair[0] for pair in anchor_neg_pair]\n",
    "# pos_pair = []\n",
    "# neg_pair = []\n",
    "# for anchor,pos,val in anchor_pos_pair:\n",
    "#     if(anchor in anchor_for_neg):\n",
    "#         idx = anchor_for_neg.index(anchor)\n",
    "#         anchor_pos_neg_triple.append((anchor,pos,anchor_neg_pair[idx][1]))\n",
    "#         pos_pair.append((pos,val))\n",
    "#         neg_pair.append((anchor_neg_pair[idx][1],anchor_neg_pair[idx][2]))\n",
    "#         anchor_for_neg.pop(idx)\n",
    "#         anchor_neg_pair.pop(idx)\n",
    "\n",
    "\n",
    "\n",
    "# anchor_dict = defaultdict(list)\n",
    "# anchor_pos_neg_triple = []\n",
    "# pos_pair = []\n",
    "# neg_pair = []\n",
    "# for anchor,neg,val in anchor_neg_pair:\n",
    "#     anchor_dict[anchor].append((anchor,neg,val))\n",
    "# for anchor,pos,val in anchor_pos_pair:\n",
    "#     if(anchor in anchor_dict.keys()):\n",
    "#         idx = random.randrange(0, len(anchor_dict[anchor]))\n",
    "#         anchor_pos_neg_triple.append((anchor,pos,anchor_dict[anchor][idx][1]))\n",
    "#         pos_pair.append((pos,val))\n",
    "#         neg_pair.append((anchor_dict[anchor][idx][1],anchor_dict[anchor][idx][2]))\n",
    "#         #anchor_dict[anchor].pop(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d0ddb12-7f75-43ff-8167-456cb53d0995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir2 = '../data1/node_similarities/'+current_model\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.colors as mcolors\n",
    "# def histogram2(all_pairs):\n",
    "#     # print(len(cosine_sim_pairs))\n",
    "#     # print(len(cosine_sim_pairs[0]))\n",
    "#     # for row in cosine_sim_pairs:\n",
    "#     #     print(row[0][1], row[1][1])\n",
    "#     #Extract the cosine similarity values from the filtered results\n",
    "#     #cosine_sim_values = [pair[1] for row in cosine_sim_pairs for pair in row[-30:]]\n",
    "#     cosine_sim_values = [pair[1] for pair in all_pairs]\n",
    "    \n",
    "#     # Define the bins for the histogram\n",
    "#     bins = np.arange(0, 1.1, 0.1)  # Bins from 0 to 1 with step size 0.1\n",
    "    \n",
    "#     # Create the histogram\n",
    "#     plt.hist(cosine_sim_values, bins=bins, edgecolor='black')\n",
    "    \n",
    "#     # Set the x-axis and y-axis labels\n",
    "#     plt.xlabel('Cosine Similarity')\n",
    "#     plt.ylabel('Frequency')\n",
    "    \n",
    "#     # Set the title of the histogram\n",
    "#     plt.title('Attack & Weak Positive')\n",
    "#     plt.savefig(dir2+'/histogram_pos_t_40.png',dpi=300)\n",
    "#     # Show the plot\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e819b0e-9a29-457d-a202-9ef32f650d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram2(pos_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a26753f-5036-463f-9e5c-45bd1c59858a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram2(neg_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "018b826b-37d6-4e54-94e6-3754a31c5fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('../data/pos_neg_sample/anchor_pos_neg_triple_4.pkl', 'wb') as f:\n",
    "#     pickle.dump(anchor_pos_neg_triple, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d5bcf0d-fbee-4eb6-b3cb-565dccf9ea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/pos_neg_sample/anchor_pos_neg_triple_1.pkl', 'rb') as f:\n",
    "#     x=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e445560f-c681-4d35-85ca-c81de030b45a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab2adb3-4a5e-438b-bbaa-f9a4f569a21e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
