{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2f13e35-4125-43a0-ad49-99b0e4386336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Optimized\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import sys\n",
    "#base_dir = os.environ['AWEB_DIR']\n",
    "sys.path.append(\"../../\")\n",
    "import config\n",
    "import pickle\n",
    "from scipy.stats import percentileofscore\n",
    "# Approach1: top and bottom similar for each weak and attack\n",
    "# anchor nodes: 1136\n",
    "# postive nodes: 668\n",
    "# negative nodes : 490\n",
    "\n",
    "# Sample 2 pt_gpt: using thresold pos=0.65, neg=0.45 select anchors that present both in positive and negative.\n",
    "# pos pair 82554\n",
    "# neg pair 30772\n",
    "# anchor nodes: 893\n",
    "# postive nodes: 536\n",
    "# negative nodes : 212\n",
    "\n",
    "# Sample 2 ft_gpt: using thresold pos=0.45, neg=0.30 select anchors that present both in positive and negative.\n",
    "# pos pair 70878\n",
    "# neg pair 55820\n",
    "# anchor nodes: 1034\n",
    "# postive nodes: 765\n",
    "# negative nodes : 618"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6391ea32-3b7d-4f8e-b2ef-f46a73d0b017",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"pt_SecRoBERTa\",\"SecRoBERTa\",\"pt_SecureBERT\",\"SecureBERT\",\"pt_gpt2-xl\",\"gpt2-xl\"]\n",
    "result_dir = config.OUTPUT_DIR\n",
    "embeddings_dir = config.EMBEDDING_DIR\n",
    "data_dir = config.DATA_DIR\n",
    "model_name = models[4]\n",
    "top_percentage = 0.03\n",
    "bottom_percentage = 0.03\n",
    "cwe_per_attack = 30\n",
    "attack_per_cwe = 100\n",
    "positive_threshold = 0.65\n",
    "negative_threshold = 0.45\n",
    "text_emb_dir = embeddings_dir+model_name+\"/\"\n",
    "output_dir = result_dir+\"gcl_data/\"+model_name+\"/\"\n",
    "# Assuming predefined weights are stored in a numpy array named 'predefined_embeddings1_weights'\n",
    "text_embeddings = np.load(text_emb_dir+'text_embeddings.npy')\n",
    "hop_text_embeddings = np.load(text_emb_dir+'text_hop_embeddings.npy')\n",
    "deepwalk_embeddings = np.load(embeddings_dir+'deepwalk.npy')\n",
    "with open(data_dir+\"doc_id_to_emb_id.json\") as f:\n",
    "    doc_id_to_emb_id = json.load(f)\n",
    "with open(data_dir+\"emb_id_to_doc_id.json\") as f:\n",
    "    emb_id_to_doc_id = json.load(f)\n",
    "with open(data_dir+'attack_weak_range.json') as fp:\n",
    "    attack_weak_range = json.load(fp)\n",
    "with open(output_dir+'/attack_text.pkl','rb') as f:\n",
    "    attack_sim = pickle.load(f)\n",
    "with open(output_dir+'/weak_text.pkl','rb') as f:\n",
    "    weak_sim = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dc84875-cf39-42b0-abb7-816ccb7df989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Placeholder function for generating text embeddings\n",
    "# def get_text_embeddings(text_embeddings, nodes):\n",
    "#     return [text_embeddings[node] for node in nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20dcf661-51f8-412f-8905-08f083e352ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_range = attack_weak_range['attack']\n",
    "weak_range = attack_weak_range['cwe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36ec9681-81a1-4ac2-8d5b-957669cf263b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attack': [0, 2043], 'cwe': [2043, 2982], 'n_nodes': 2982}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attack_weak_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2129d2a5-001a-44ba-8d1b-0173be042b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for both sets of nodes\n",
    "attack_nodes = list(range(attack_range[0],attack_range[1]))\n",
    "weakness_nodes = list(range(weak_range[0],weak_range[1]))\n",
    "attack_embeddings = text_embeddings[attack_nodes]\n",
    "weakness_embeddings = text_embeddings[weakness_nodes]\n",
    "hop_attack_embeddings = hop_text_embeddings[attack_nodes]\n",
    "hop_weakness_embeddings = hop_text_embeddings[weakness_nodes]\n",
    "\n",
    "deepwalk_attack_embeddings = deepwalk_embeddings[attack_nodes]\n",
    "deepwalk_weakness_embeddings = deepwalk_embeddings[weakness_nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e137ad65-e7b4-46f4-8291-50dded01d015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity between all pairs of nodes\n",
    "text_weak_attack_matrix = cosine_similarity(weakness_embeddings, attack_embeddings)\n",
    "# Compute cosine similarity between all pairs of nodes\n",
    "text_attack_weak_matrix = cosine_similarity(attack_embeddings, weakness_embeddings)\n",
    "\n",
    "# # Compute cosine similarity between all pairs of nodes\n",
    "# hop_weak_attack_matrix = cosine_similarity(hop_weakness_embeddings, hop_attack_embeddings)\n",
    "# # Compute cosine similarity between all pairs of nodes\n",
    "# hop_attack_weak_matrix = cosine_similarity(hop_attack_embeddings, hop_weakness_embeddings)\n",
    "\n",
    "# # Compute cosine similarity between all pairs of nodes\n",
    "# deepwalk_weak_attack_matrix = cosine_similarity(deepwalk_weakness_embeddings, deepwalk_attack_embeddings)\n",
    "# # Compute cosine similarity between all pairs of nodes\n",
    "# deepwalk_attack_weak_matrix = cosine_similarity(deepwalk_attack_embeddings, deepwalk_weakness_embeddings)\n",
    "\n",
    "# Compute cosine similarity between all pairs of nodes\n",
    "deepwalk_attack_matrix = cosine_similarity(deepwalk_attack_embeddings, deepwalk_attack_embeddings)\n",
    "# Compute cosine similarity between all pairs of nodes\n",
    "deepwalk_weak_matrix = cosine_similarity(deepwalk_weakness_embeddings, deepwalk_weakness_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79d408a7-33ac-4574-95a7-b3879497446a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5let - anchor, positive-text, negative-text, positive-graph, negative-graph\n",
    "import random\n",
    "def get_sample_10(weak_attack_matrix,attack_weak_matrix, graph_weak_matrix, graph_attack_matrix,  sample_no=10):\n",
    "    anchor_pos_neg_triple = []\n",
    "    for i, attack_node in enumerate(attack_nodes):\n",
    "        # Get the similarity scores for the current attack node\n",
    "        sim_scores = attack_weak_matrix[i]\n",
    "        sim_scores2 = graph_attack_matrix[i]\n",
    "        # Get the indices of the 5 most similar and 5 least similar nodes\n",
    "        # This one is weak text positive negative\n",
    "        top5_sim_indices = np.argsort(sim_scores)[-cwe_per_attack:]  # Most similar\n",
    "        bottom5_sim_indices = np.argsort(sim_scores)[:cwe_per_attack]  # Least similar\n",
    "\n",
    "        # Here 2 means attack graph positive negative\n",
    "        top5_sim_indices2 = np.argsort(sim_scores2)[-cwe_per_attack:]  # Most similar\n",
    "        bottom5_sim_indices2 = np.argsort(sim_scores2)[:cwe_per_attack]  # Least similar\n",
    "        \n",
    "        # Select the most similar positive nodes\n",
    "        # Select the least similar negative nodes\n",
    "        for j in range(len(top5_sim_indices)):\n",
    "            idx1 = top5_sim_indices[j]\n",
    "            idx2 = bottom5_sim_indices[j]\n",
    "            idx3 = top5_sim_indices2[j]\n",
    "            idx4 = bottom5_sim_indices2[j]\n",
    "            anchor_pos_neg_triple.append((attack_node, weakness_nodes[idx1], weakness_nodes[idx2], attack_nodes[idx3], attack_nodes[idx4] ))\n",
    "\n",
    "\n",
    "    \n",
    "    for i, weak_node in enumerate(weakness_nodes):\n",
    "        # Get the similarity scores for the current attack node\n",
    "        sim_scores = weak_attack_matrix[i]\n",
    "        sim_scores2 = graph_weak_matrix[i]\n",
    "        # Get the indices of the 5 most similar and 5 least similar nodes\n",
    "        top5_sim_indices = np.argsort(sim_scores)[-attack_per_cwe:]  # Most similar\n",
    "        bottom5_sim_indices = np.argsort(sim_scores)[:attack_per_cwe]  # Least similar\n",
    "\n",
    "        # Here 2 means attack graph positive negative\n",
    "        top5_sim_indices2 = np.argsort(sim_scores2)[-attack_per_cwe:]  # Most similar\n",
    "        bottom5_sim_indices2 = np.argsort(sim_scores2)[:attack_per_cwe]  # Least similar\n",
    "        \n",
    "        # Select the most similar positive nodes\n",
    "        # Select the least similar negative nodes\n",
    "        for j in range(len(top5_sim_indices)):\n",
    "            idx1 = top5_sim_indices[j]\n",
    "            idx2 = bottom5_sim_indices[j]\n",
    "            idx3 = top5_sim_indices2[j]\n",
    "            idx4 = bottom5_sim_indices2[j]\n",
    "            anchor_pos_neg_triple.append((weak_node, attack_nodes[idx1], attack_nodes[idx2],weakness_nodes[idx3], weakness_nodes[idx4]))\n",
    "    anchor_set = set()\n",
    "    positive_set=set()\n",
    "    negative_set=set()   \n",
    "    positive_set2=set()\n",
    "    negative_set2=set()\n",
    "    \n",
    "    for a,p,n,pg,ng in anchor_pos_neg_triple:\n",
    "        anchor_set.add(a)\n",
    "        positive_set.add(p)\n",
    "        negative_set.add(n)\n",
    "        positive_set2.add(pg)\n",
    "        negative_set2.add(ng)\n",
    "        if(a>=weak_range[1] or p>=weak_range[1] or n>=weak_range[1]):\n",
    "            print(a,\" \",p,\" \", n)\n",
    "    print(\"# anchor nodes:\",len(anchor_set))\n",
    "    print(\"# text-postive nodes:\",len(positive_set))\n",
    "    print(\"# text-negative nodes :\",len(negative_set))\n",
    "    \n",
    "    print(\"# text-not selected pos :\",len(anchor_set-positive_set))\n",
    "    print(\"# text-not selected neg  :\",len(anchor_set-negative_set))\n",
    "    print(\"# text-not selected intersect :\",len((anchor_set-positive_set)&(anchor_set-negative_set)))\n",
    "\n",
    "    \n",
    "    print(\"# graph-postive nodes:\",len(positive_set2))\n",
    "    print(\"# graph-negative nodes :\",len(negative_set2))\n",
    "\n",
    "    print(\"# graph-not selected pos :\",len(anchor_set-positive_set2))\n",
    "    print(\"# graph-not selected neg  :\",len(anchor_set-negative_set2))\n",
    "    print(\"# graph-not selected intersect :\",len((anchor_set-positive_set2)&(anchor_set-negative_set2)))\n",
    "    \n",
    "    print(\"# examples: \", len(anchor_pos_neg_triple))\n",
    "    random.shuffle(anchor_pos_neg_triple)\n",
    "    save_file = output_dir+'anchor_pos_neg_triple_{}.pkl'.format(sample_no)\n",
    "    with open(save_file, 'wb') as f:\n",
    "        print(\"Save at:\", save_file)\n",
    "        pickle.dump(anchor_pos_neg_triple, f)\n",
    "    return anchor_pos_neg_triple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ade7a1a0-88fa-41a8-8fb3-60f84fb2e734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# anchor nodes: 2982\n",
      "# text-postive nodes: 1891\n",
      "# text-negative nodes : 1079\n",
      "# text-not selected pos : 1091\n",
      "# text-not selected neg  : 1903\n",
      "# text-not selected intersect : 478\n",
      "# graph-postive nodes: 2982\n",
      "# graph-negative nodes : 2968\n",
      "# graph-not selected pos : 0\n",
      "# graph-not selected neg  : 14\n",
      "# graph-not selected intersect : 0\n",
      "# examples:  155190\n",
      "Save at: /home/afarhan/post-doc/AWEB_GCL/model_outputs/enterprise_attack/gcl_data/pt_gpt2-xl/anchor_pos_neg_triple_10.pkl\n"
     ]
    }
   ],
   "source": [
    "anchor_pos_neg_triple = get_sample_10(text_weak_attack_matrix,text_attack_weak_matrix,deepwalk_weak_matrix,deepwalk_attack_matrix, sample_no=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11d21cb6-22cd-4700-b9fa-f888709aff72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# anchor nodes: 2982\n",
      "# postive nodes: 1891\n",
      "# negative nodes : 1079\n",
      "# examples:  155190\n",
      "Save at: /home/afarhan/post-doc/AWEB_GCL/model_outputs/enterprise_attack/gcl_data/pt_gpt2-xl/anchor_pos_neg_triple_1.pkl\n"
     ]
    }
   ],
   "source": [
    "def get_sample_1(weak_attack_matrix,attack_weak_matrix, sample_no=1):\n",
    "    anchor_pos_neg_triple = []\n",
    "    for i, attack_node in enumerate(attack_nodes):\n",
    "        # Get the similarity scores for the current attack node\n",
    "        sim_scores = attack_weak_matrix[i]\n",
    "        \n",
    "        # Get the indices of the 5 most similar and 5 least similar nodes\n",
    "        top5_sim_indices = np.argsort(sim_scores)[-cwe_per_attack:]  # Most similar\n",
    "        bottom5_sim_indices = np.argsort(sim_scores)[:cwe_per_attack]  # Least similar\n",
    "        \n",
    "        # Select the most similar positive nodes\n",
    "        # Select the least similar negative nodes\n",
    "        for j in range(len(top5_sim_indices)):\n",
    "            idx1 = top5_sim_indices[j]\n",
    "            idx2 = bottom5_sim_indices[j]\n",
    "            anchor_pos_neg_triple.append((attack_node, weakness_nodes[idx1], weakness_nodes[idx2]))\n",
    "    for i, weak_node in enumerate(weakness_nodes):\n",
    "        # Get the similarity scores for the current attack node\n",
    "        sim_scores = weak_attack_matrix[i]\n",
    "        \n",
    "        # Get the indices of the 5 most similar and 5 least similar nodes\n",
    "        top5_sim_indices = np.argsort(sim_scores)[-attack_per_cwe:]  # Most similar\n",
    "        bottom5_sim_indices = np.argsort(sim_scores)[:attack_per_cwe]  # Least similar\n",
    "        \n",
    "        # Select the most similar positive nodes\n",
    "        # Select the least similar negative nodes\n",
    "        for j in range(len(top5_sim_indices)):\n",
    "            idx1 = top5_sim_indices[j]\n",
    "            idx2 = bottom5_sim_indices[j]\n",
    "            anchor_pos_neg_triple.append((weak_node, attack_nodes[idx1], attack_nodes[idx2]))\n",
    "    anchor_set = set()\n",
    "    positive_set=set()\n",
    "    negative_set=set()\n",
    "    for a,p,n in anchor_pos_neg_triple:\n",
    "        anchor_set.add(a)\n",
    "        positive_set.add(p)\n",
    "        negative_set.add(n)\n",
    "        if(a>=weak_range[1] or p>=weak_range[1] or n>=weak_range[1]):\n",
    "            print(a,\" \",p,\" \", n)\n",
    "    print(\"# anchor nodes:\",len(anchor_set))\n",
    "    print(\"# postive nodes:\",len(positive_set))\n",
    "    print(\"# negative nodes :\",len(negative_set))\n",
    "    print(\"# examples: \", len(anchor_pos_neg_triple))\n",
    "    save_file = output_dir+'anchor_pos_neg_triple_{}.pkl'.format(sample_no)\n",
    "    with open(save_file, 'wb') as f:\n",
    "        print(\"Save at:\", save_file)\n",
    "        pickle.dump(anchor_pos_neg_triple, f)\n",
    "    return anchor_pos_neg_triple\n",
    "anchor_pos_neg_triple = get_sample_1(text_weak_attack_matrix,text_attack_weak_matrix, sample_no=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e75cb0-6ba4-41a4-92f2-c6d2600b18ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_bottom_pairs_row(i,sim_values, top_percentage,bottom_percentage, isAttack):\n",
    "    top_threshold = np.percentile(sim_values, 100 - top_percentage * 100)\n",
    "    bottom_threshold = np.percentile(sim_values, bottom_percentage * 100)\n",
    "    # print(\"top_threshold\",top_threshold)\n",
    "    # print(\"bottom_threshold\",bottom_threshold)\n",
    "    top_pairs = []\n",
    "    bottom_pairs = []\n",
    "    for j in range(len(sim_values)):\n",
    "        if(isAttack):\n",
    "            \n",
    "            neighbor_id = weakness_nodes[j]\n",
    "        else:\n",
    "            \n",
    "            neighbor_id = attack_nodes[j]\n",
    "        if sim_values[j] >= top_threshold:\n",
    "            top_pairs.append((neighbor_id, sim_values[j]))\n",
    "        elif sim_values[j] <= bottom_threshold:\n",
    "            bottom_pairs.append((neighbor_id, sim_values[j]))\n",
    "    return top_pairs, bottom_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75810e6e-882c-4f0a-9364-194663869d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import random\n",
    "def get_sample_11(weak_attack_matrix,attack_weak_matrix, graph_weak_matrix, graph_attack_matrix,  sample_no=11):\n",
    "    top_percentage=0.04\n",
    "    bottom_percentage=0.04\n",
    "    anchor_pos_neg_triple = []\n",
    "    for i, attack_node in enumerate(attack_nodes):\n",
    "        # Get the index pairs for the top and bottom 25%\n",
    "        anchor_pos_pair1, anchor_neg_pair1 = get_top_bottom_pairs_row(i,attack_weak_matrix[i], top_percentage, bottom_percentage, True)\n",
    "        anchor_pos_pair2, anchor_neg_pair2 = get_top_bottom_pairs_row(i,graph_attack_matrix[i], top_percentage+0.12, bottom_percentage+0.12, False)\n",
    "        print(len(anchor_pos_pair1))\n",
    "        print(len(anchor_pos_pair2))\n",
    "        #Sort pairs\n",
    "        anchor_pos_pair1.sort(reverse=True, key=lambda x: x[1])\n",
    "        anchor_neg_pair1.sort(key=lambda x: x[1])\n",
    "        anchor_pos_pair2.sort(reverse=True, key=lambda x: x[1])\n",
    "        anchor_neg_pair2.sort(key=lambda x: x[1])\n",
    "\n",
    "        for j in range(len(anchor_pos_pair1)):\n",
    "            #text better\n",
    "            pos1,_ = anchor_pos_pair1[j]\n",
    "            neg1,_ = anchor_neg_pair1[j]\n",
    "            #graph poor\n",
    "            randi = random.randrange(0, len(anchor_pos_pair2))\n",
    "            pos2,_ = anchor_pos_pair2[randi]\n",
    "            neg2,_ = anchor_neg_pair2[randi]\n",
    "            anchor_pos_neg_triple.append((attack_node, pos1,neg1,pos2,neg2 ))\n",
    "        \n",
    "    print(\"Attack\")\n",
    "    print(len(anchor_pos_neg_triple))\n",
    "    for i, weak_node in enumerate(weakness_nodes):\n",
    "        # Get the index pairs for the top and bottom 25%\n",
    "        anchor_pos_pair1, anchor_neg_pair1 = get_top_bottom_pairs_row(i,weak_attack_matrix[i], top_percentage+0.12, bottom_percentage+0.12, False)\n",
    "        anchor_pos_pair2, anchor_neg_pair2 = get_top_bottom_pairs_row(i,graph_weak_matrix[i], top_percentage, bottom_percentage, True)\n",
    "        #Sort pairs\n",
    "        anchor_pos_pair1.sort(reverse=True, key=lambda x: x[1])\n",
    "        anchor_neg_pair1.sort(key=lambda x: x[1])\n",
    "        anchor_pos_pair2.sort(reverse=True, key=lambda x: x[1])\n",
    "        anchor_neg_pair2.sort(key=lambda x: x[1])\n",
    "        # print(\"Weak\")\n",
    "        # print(len(anchor_pos_pair1))\n",
    "        # print(len(anchor_neg_pair1))\n",
    "\n",
    "        # Make triplets (anchor, positive, negative)\n",
    "        for j in range(len(anchor_pos_pair2)):\n",
    "            #text poor\n",
    "            randi = random.randrange(0, len(anchor_pos_pair1))\n",
    "            pos1,_ = anchor_pos_pair1[randi]\n",
    "            neg1,_ = anchor_neg_pair1[randi]\n",
    "            #graph better\n",
    "            pos2,_ = anchor_pos_pair2[j]\n",
    "            neg2,_ = anchor_neg_pair2[j]\n",
    "            anchor_pos_neg_triple.append((weak_node, pos1,neg1,pos2,neg2 ))\n",
    "\n",
    "    anchor_set = set()\n",
    "    positive_set=set()\n",
    "    negative_set=set()   \n",
    "    positive_set2=set()\n",
    "    negative_set2=set()\n",
    "    \n",
    "    for a,p,n,pg,ng in anchor_pos_neg_triple:\n",
    "        anchor_set.add(a)\n",
    "        positive_set.add(p)\n",
    "        negative_set.add(n)\n",
    "        positive_set2.add(pg)\n",
    "        negative_set2.add(ng)\n",
    "        if(a>=weak_range[1] or p>=weak_range[1] or n>=weak_range[1]):\n",
    "            print(a,\" \",p,\" \", n)\n",
    "    print(\"# anchor nodes:\",len(anchor_set))\n",
    "    print(\"# text-postive nodes:\",len(positive_set))\n",
    "    print(\"# text-negative nodes :\",len(negative_set))\n",
    "    \n",
    "    print(\"# text-not selected pos :\",len(anchor_set-positive_set))\n",
    "    print(\"# text-not selected neg  :\",len(anchor_set-negative_set))\n",
    "    print(\"# text-not selected intersect :\",len((anchor_set-positive_set)&(anchor_set-negative_set)))\n",
    "\n",
    "    \n",
    "    print(\"# graph-postive nodes:\",len(positive_set2))\n",
    "    print(\"# graph-negative nodes :\",len(negative_set2))\n",
    "\n",
    "    print(\"# graph-not selected pos :\",len(anchor_set-positive_set2))\n",
    "    print(\"# graph-not selected neg  :\",len(anchor_set-negative_set2))\n",
    "    print(\"# graph-not selected intersect :\",len((anchor_set-positive_set2)&(anchor_set-negative_set2)))\n",
    "    \n",
    "    print(\"# examples: \", len(anchor_pos_neg_triple))\n",
    "    random.shuffle(anchor_pos_neg_triple)\n",
    "    save_file = output_dir+'anchor_pos_neg_triple_{}.pkl'.format(sample_no)\n",
    "    with open(save_file, 'wb') as f:\n",
    "        print(\"Save at:\", save_file)\n",
    "        pickle.dump(anchor_pos_neg_triple, f)\n",
    "    return anchor_pos_neg_triple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d54b7e-9a4e-4e3d-b38c-0ec6e9faf30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_pos_neg_triple = get_sample_11(text_weak_attack_matrix,text_attack_weak_matrix,deepwalk_weak_matrix,deepwalk_attack_matrix, sample_no=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f284dfb5-b787-4c85-9366-182160f2c37e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc31b7d-94d7-461b-9e1a-51ec2da1c052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_thresholds(cosine_sim_matrix, top_percentage=0.15, bottom_percentage=0.15):\n",
    "    # Flatten the matrix to get a list of all similarity values\n",
    "    flat_sim_values = cosine_sim_matrix.flatten()\n",
    "    # Calculate the thresholds for the top and bottom percentages\n",
    "    top_threshold = np.percentile(flat_sim_values, 100 - top_percentage * 100)\n",
    "    bottom_threshold = np.percentile(flat_sim_values, bottom_percentage * 100)\n",
    "    return top_threshold, bottom_threshold\n",
    "\n",
    "def get_top_bottom_pairs(cosine_sim_matrix, top_threshold, bottom_threshold, isAttack):\n",
    "    top_pairs = []\n",
    "    bottom_pairs = []\n",
    "    for i in range(cosine_sim_matrix.shape[0]):\n",
    "        for j in range(cosine_sim_matrix.shape[1]):\n",
    "            if(isAttack):\n",
    "                anchor_id = attack_nodes[i]\n",
    "                neighbor_id = weakness_nodes[j]\n",
    "            else:\n",
    "                anchor_id = weakness_nodes[i]\n",
    "                neighbor_id = attack_nodes[j]\n",
    "            if cosine_sim_matrix[i, j] >= top_threshold:\n",
    "                top_pairs.append((anchor_id, neighbor_id, cosine_sim_matrix[i, j]))\n",
    "            elif cosine_sim_matrix[i, j] <= bottom_threshold:\n",
    "                bottom_pairs.append((anchor_id, neighbor_id, cosine_sim_matrix[i, j]))\n",
    "    return top_pairs, bottom_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb012e2b-b383-419d-a8e5-980f11a9ffb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def get_sample_8(attack_weak_matrix,weak_attack_matrix, sample_no=8):\n",
    "    anchor_pos_neg_triple = []\n",
    "\n",
    "    # Calculate the thresholds for the top 25% and bottom 25%\n",
    "    top_threshold, bottom_threshold = get_similarity_thresholds(attack_weak_matrix)\n",
    "    \n",
    "    # Get the index pairs for the top and bottom 25%\n",
    "    anchor_pos_pair1, anchor_neg_pair1 = get_top_bottom_pairs(attack_weak_matrix, top_threshold, bottom_threshold, True)\n",
    "\n",
    "    #Sort pairs\n",
    "    anchor_pos_pair1.sort(reverse=True, key=lambda x: x[2])\n",
    "    anchor_neg_pair1.sort(key=lambda x: x[2])\n",
    "\n",
    "    print(len(anchor_pos_pair1))\n",
    "    print(len(anchor_neg_pair1))\n",
    "    \n",
    "    # Make triplets (anchor, positive, negative)\n",
    "\n",
    "    anchor_neg_dict = defaultdict(list)\n",
    "    \n",
    "    for anchor, neg, val in anchor_neg_pair1:\n",
    "        anchor_neg_dict[anchor].append((neg, val))\n",
    "    \n",
    "    for anchor, pos, pos_val in anchor_pos_pair1:\n",
    "        if anchor in anchor_neg_dict and anchor_neg_dict[anchor]:\n",
    "            neg, neg_val = anchor_neg_dict[anchor].pop(0)\n",
    "            anchor_pos_neg_triple.append((anchor, pos, neg))\n",
    "\n",
    "    # Calculate the thresholds for the top 25% and bottom 25%\n",
    "    top_threshold, bottom_threshold = get_similarity_thresholds(weak_attack_matrix)\n",
    "    \n",
    "    # Get the index pairs for the top and bottom 25%\n",
    "    anchor_pos_pair1, anchor_neg_pair1 = get_top_bottom_pairs(weak_attack_matrix, top_threshold, bottom_threshold, False)\n",
    "\n",
    "    #Sort pairs\n",
    "    anchor_pos_pair1.sort(reverse=True, key=lambda x: x[2])\n",
    "    anchor_neg_pair1.sort(key=lambda x: x[2])\n",
    "\n",
    "    print(len(anchor_pos_pair1))\n",
    "    print(len(anchor_neg_pair1))\n",
    "    \n",
    "    # Make triplets (anchor, positive, negative)\n",
    "\n",
    "    anchor_neg_dict = defaultdict(list)\n",
    "    \n",
    "    for anchor, neg, val in anchor_neg_pair1:\n",
    "        anchor_neg_dict[anchor].append((neg, val))\n",
    "    \n",
    "    for anchor, pos, pos_val in anchor_pos_pair1:\n",
    "        if anchor in anchor_neg_dict and anchor_neg_dict[anchor]:\n",
    "            neg, neg_val = anchor_neg_dict[anchor].pop(0)\n",
    "            anchor_pos_neg_triple.append((anchor, pos, neg))\n",
    "\n",
    "\n",
    "    \n",
    "    anchor_set = set()\n",
    "    positive_set=set()\n",
    "    negative_set=set()\n",
    "    for a,p,n in anchor_pos_neg_triple:\n",
    "        anchor_set.add(a)\n",
    "        positive_set.add(p)\n",
    "        negative_set.add(n)\n",
    "        if(a>=weak_range[1] or p>=weak_range[1] or n>=weak_range[1]):\n",
    "            print(a,\" \",p,\" \", n)\n",
    "    print(\"# anchor nodes:\",len(anchor_set))\n",
    "    print(\"# postive nodes:\",len(positive_set))\n",
    "    print(\"# negative nodes :\",len(negative_set))\n",
    "    print(\"# Sample:\",len(anchor_pos_neg_triple))\n",
    "    \n",
    "    save_file = output_dir+'anchor_pos_neg_triple_{}.pkl'.format(sample_no)\n",
    "    with open(save_file, 'wb') as f:\n",
    "        print(\"Save at:\", save_file)\n",
    "        pickle.dump(anchor_pos_neg_triple, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310996ad-20f9-4b4b-bf24-6c7934e28bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_bottom_pairs_row(i,sim_values, top_percentage,bottom_percentage, isAttack):\n",
    "    top_threshold = np.percentile(sim_values, 100 - top_percentage * 100)\n",
    "    bottom_threshold = np.percentile(sim_values, bottom_percentage * 100)\n",
    "    print(\"top_threshold\",top_threshold)\n",
    "    print(\"bottom_threshold\",bottom_threshold)\n",
    "    top_pairs = []\n",
    "    bottom_pairs = []\n",
    "    for j in range(len(sim_values)):\n",
    "        if(isAttack):\n",
    "            anchor_id = attack_nodes[i]\n",
    "            neighbor_id = weakness_nodes[j]\n",
    "        else:\n",
    "            anchor_id = weakness_nodes[i]\n",
    "            neighbor_id = attack_nodes[j]\n",
    "        if sim_values[j] >= top_threshold:\n",
    "            top_pairs.append((anchor_id, neighbor_id, sim_values[j]))\n",
    "        elif sim_values[j] <= bottom_threshold:\n",
    "            bottom_pairs.append((anchor_id, neighbor_id, sim_values[j]))\n",
    "    return top_pairs, bottom_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bd712b-d3a6-452e-b68e-cc86b7c0a47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def get_sample_9(attack_weak_matrix,weak_attack_matrix, sample_no=9):\n",
    "    top_percentage=0.051\n",
    "    bottom_percentage=0.051\n",
    "    anchor_pos_neg_triple = []\n",
    "    for i in range(len(attack_weak_matrix)):\n",
    "        # Get the index pairs for the top and bottom 25%\n",
    "        anchor_pos_pair1, anchor_neg_pair1 = get_top_bottom_pairs_row(i,attack_weak_matrix[i], top_percentage, bottom_percentage, True)\n",
    "    \n",
    "        #Sort pairs\n",
    "        anchor_pos_pair1.sort(reverse=True, key=lambda x: x[2])\n",
    "        anchor_neg_pair1.sort(key=lambda x: x[2])\n",
    "        # print(\"Attack\")\n",
    "        # print(len(anchor_pos_pair1))\n",
    "        # print(len(anchor_neg_pair1))\n",
    "    \n",
    "        # Make triplets (anchor, positive, negative)\n",
    "        anchor_neg_dict = defaultdict(list)\n",
    "        \n",
    "        for anchor, neg, val in anchor_neg_pair1:\n",
    "            anchor_neg_dict[anchor].append((neg, val))\n",
    "        \n",
    "        for anchor, pos, pos_val in anchor_pos_pair1:\n",
    "            if anchor in anchor_neg_dict and anchor_neg_dict[anchor]:\n",
    "                neg, neg_val = anchor_neg_dict[anchor].pop(0)\n",
    "                anchor_pos_neg_triple.append((anchor, pos, neg))\n",
    "    print(\"Attack\")\n",
    "    \n",
    "    print(len(anchor_pos_neg_triple))\n",
    "    for i in range(len(weak_attack_matrix)):\n",
    "        # Get the index pairs for the top and bottom 25%\n",
    "        anchor_pos_pair1, anchor_neg_pair1 = get_top_bottom_pairs_row(i,weak_attack_matrix[i], top_percentage, bottom_percentage, False)\n",
    "    \n",
    "        #Sort pairs\n",
    "        anchor_pos_pair1.sort(reverse=True, key=lambda x: x[2])\n",
    "        anchor_neg_pair1.sort(key=lambda x: x[2])\n",
    "        # print(\"Weak\")\n",
    "        # print(len(anchor_pos_pair1))\n",
    "        # print(len(anchor_neg_pair1))\n",
    "    \n",
    "        # Make triplets (anchor, positive, negative)\n",
    "        anchor_neg_dict = defaultdict(list)\n",
    "        \n",
    "        for anchor, neg, val in anchor_neg_pair1:\n",
    "            anchor_neg_dict[anchor].append((neg, val))\n",
    "        \n",
    "        for anchor, pos, pos_val in anchor_pos_pair1:\n",
    "            if anchor in anchor_neg_dict and anchor_neg_dict[anchor]:\n",
    "                neg, neg_val = anchor_neg_dict[anchor].pop(0)\n",
    "                anchor_pos_neg_triple.append((anchor, pos, neg))\n",
    "\n",
    "    print(\"Weak\")\n",
    "    print(len(anchor_pos_pair1))\n",
    "    print(len(anchor_neg_pair1))\n",
    "    print(anchor_pos_neg_triple[-10:])\n",
    "    anchor_set = set()\n",
    "    positive_set=set()\n",
    "    negative_set=set()\n",
    "    for a,p,n in anchor_pos_neg_triple:\n",
    "        anchor_set.add(a)\n",
    "        positive_set.add(p)\n",
    "        negative_set.add(n)\n",
    "        if(a>=weak_range[1] or p>=weak_range[1] or n>=weak_range[1]):\n",
    "            print(a,\" \",p,\" \", n)\n",
    "    print(\"# anchor nodes:\",len(anchor_set))\n",
    "    print(\"# text-postive nodes:\",len(positive_set))\n",
    "    print(\"# text-negative nodes :\",len(negative_set))\n",
    "    \n",
    "    print(\"# text-not selected pos :\",len(anchor_set-positive_set))\n",
    "    print(\"# text-not selected neg  :\",len(anchor_set-negative_set))\n",
    "    print(\"# text-not selected intersect :\",len((anchor_set-positive_set)&(anchor_set-negative_set)))\n",
    "\n",
    "    \n",
    "    save_file = output_dir+'anchor_pos_neg_triple_{}.pkl'.format(sample_no)\n",
    "    with open(save_file, 'wb') as f:\n",
    "        print(\"Save at:\", save_file)\n",
    "        pickle.dump(anchor_pos_neg_triple, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2d19c0-862e-486f-94de-dc1e2815a141",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sample_9(text_attack_weak_matrix,text_weak_attack_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b21a308-d2d8-430d-aa44-30e361450328",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3252cf4a-a29a-4054-9ca4-57e0b6057b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.colors as mcolors\n",
    "# def histogram(cosine_sim_pairs, analysis_model):\n",
    "#     # Extract the cosine similarity values from the filtered results\n",
    "#     cosine_sim_values = [item for row in cosine_sim_pairs for item in row]\n",
    "#     # Define the bins for the histogram\n",
    "#     bins = np.arange(0, 1.1, 0.05)  # Bins from 0 to 1 with step size 0.1\n",
    "#     plt.figure(figsize=(5, 3))\n",
    "#     # Create the histogram\n",
    "#     plt.hist(cosine_sim_values, bins=bins, edgecolor='black')\n",
    "    \n",
    "#     # Set the x-axis and y-axis labels\n",
    "#     plt.xlabel('Cosine Similarity')\n",
    "#     plt.ylabel('Frequency')\n",
    "#     xt = np.arange(0,1.1,0.1)\n",
    "#     plt.xticks(xt)\n",
    "    \n",
    "#     # Set the title of the histogram\n",
    "#     plt.title('Attack to CWE Text Sim. in '+analysis_model)\n",
    "#     output_dir = result_dir+\"gcl_data/\"+analysis_model\n",
    "#     plt.savefig(output_dir+'/attack_cwe_text_sim_histogram.png',dpi=200)\n",
    "#     # Show the plot\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e444495-d878-4167-adfe-f86cf81a4c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram(text_attack_weak_matrix, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a19b116-8d1d-4e9e-a47f-c30d9d422512",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Approach6: 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56827979-6d2f-43d6-833d-40b75621a756",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6659e5-3b08-402d-b994-3009e4603e1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8275a1fb-9a99-44d2-89ea-1fafc7cd1f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach1: using top and bottom similar for each weak and attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28de2277-11ab-4905-9bf4-17974f24c787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3786e7-b6bd-4100-bf1a-2310d46f2acd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee1319f-b61d-4c9b-b6a4-163902440832",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = config.DATA_DIR\n",
    "with open(data_dir+'graph_edges.json') as f:\n",
    "    combined_edges=json.load(f)\n",
    "len(combined_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e8e40d-09a7-4774-b2ec-8f77f9e7c585",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a,p,n in anchor_pos_neg_triple:\n",
    "    combined_edges.append([a,p])\n",
    "len(combined_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf96947-1ade-4015-8a20-dd0130d7b88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_edges[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b849e50-d73f-4be6-ae2a-90cd01befb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(output_dir+'graph_edges_sample_1.json', 'w') as f:\n",
    "#     json.dump(combined_edges, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5bbc0e-a929-493a-a736-0f618d7c0d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_2():\n",
    "    anchor_pos_pair2 = []\n",
    "    anchor_neg_pair2 = []\n",
    "    \n",
    "    # Find anchor-positive and anchor-negative pairs based on thresholds\n",
    "    weakness_idxs, attack_idxs = np.where(attack_weak_matrix >= positive_threshold)\n",
    "    anchor_pos_pair2.extend([(attack_nodes[i], weakness_nodes[j], attack_weak_matrix[i, j]) for i, j in zip(weakness_idxs, attack_idxs)])\n",
    "    \n",
    "    weakness_idxs, attack_idxs = np.where(attack_weak_matrix <= negative_threshold)\n",
    "    anchor_neg_pair2.extend([(attack_nodes[i], weakness_nodes[j], attack_weak_matrix[i, j]) for i, j in zip(weakness_idxs, attack_idxs)])\n",
    "    \n",
    "    attack_idxs, weakness_idxs = np.where(weak_attack_matrix >= positive_threshold)\n",
    "    anchor_pos_pair2.extend([(weakness_nodes[i], attack_nodes[j], weak_attack_matrix[i, j]) for i, j in zip(attack_idxs, weakness_idxs)])\n",
    "    \n",
    "    attack_idxs, weakness_idxs = np.where(weak_attack_matrix <= negative_threshold)\n",
    "    anchor_neg_pair2.extend([(weakness_nodes[i], attack_nodes[j], weak_attack_matrix[i, j]) for i, j in zip(attack_idxs, weakness_idxs)])\n",
    "    \n",
    "    #Sort pairs\n",
    "    anchor_pos_pair2.sort(reverse=True, key=lambda x: x[2])\n",
    "    anchor_neg_pair2.sort(key=lambda x: x[2])\n",
    "    \n",
    "    print(len(anchor_pos_pair2))\n",
    "    print(len(anchor_neg_pair2))\n",
    "    \n",
    "    # Make triplets (anchor, positive, negative)\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    anchor_pos_neg_triple = []\n",
    "    anchor_neg_dict = defaultdict(list)\n",
    "    \n",
    "    for anchor, neg, val in anchor_neg_pair2:\n",
    "        anchor_neg_dict[anchor].append((neg, val))\n",
    "    \n",
    "    for anchor, pos, pos_val in anchor_pos_pair2:\n",
    "        if anchor in anchor_neg_dict and anchor_neg_dict[anchor]:\n",
    "            neg, neg_val = anchor_neg_dict[anchor].pop(0)\n",
    "            anchor_pos_neg_triple.append((anchor, pos, neg))\n",
    "    anchor_set = set()\n",
    "    positive_set=set()\n",
    "    negative_set=set()\n",
    "    for a,p,n in anchor_pos_neg_triple:\n",
    "        anchor_set.add(a)\n",
    "        positive_set.add(p)\n",
    "        negative_set.add(n)\n",
    "        if(a>=weak_range[1] or p>=weak_range[1] or n>=weak_range[1]):\n",
    "            print(a,\" \",p,\" \", n)\n",
    "    print(\"# anchor nodes:\",len(anchor_set))\n",
    "    print(\"# postive nodes:\",len(positive_set))\n",
    "    print(\"# negative nodes :\",len(negative_set))\n",
    "    print(\"# Sample:\",len(anchor_pos_neg_triple))\n",
    "    \n",
    "    th_path= output_dir+\"{}_{}/\".format(positive_threshold, negative_threshold)\n",
    "    if not os.path.exists(th_path):\n",
    "        os.makedirs(th_path)\n",
    "    with open(th_path+'anchor_pos_neg_triple_2.pkl', 'wb') as f:\n",
    "        pickle.dump(anchor_pos_neg_triple, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cd0ff2-2219-4b69-a15a-9a3f5369d6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach3: positive from attack-weak, negative from attack-attack, weak-weak\n",
    "def get_sample_3():\n",
    "    anchor_pos_neg_triple = []\n",
    "    for i, attack_node in enumerate(attack_nodes):\n",
    "        # Get the similarity scores for the current attack node\n",
    "        sim_scores = attack_weak_matrix[i]\n",
    "        sim_scores2 = hop_attack_matrix[i]\n",
    "        # Get the indices of the 5 most similar and 5 least similar nodes\n",
    "        top5_sim_indices = np.argsort(sim_scores)[-cwe_per_attack:]  # Most similar\n",
    "        bottom5_sim_indices = np.argsort(sim_scores2)[:cwe_per_attack]  # Least similar\n",
    "        \n",
    "        # Select the most similar positive nodes\n",
    "        # Select the least similar negative nodes\n",
    "        for j in range(len(top5_sim_indices)):\n",
    "            idx1 = top5_sim_indices[j]\n",
    "            idx2 = bottom5_sim_indices[j]\n",
    "            anchor_pos_neg_triple.append((attack_node, weakness_nodes[idx1], attack_nodes[idx2]))\n",
    "    for i, weak_node in enumerate(weakness_nodes):\n",
    "        # Get the similarity scores for the current attack node\n",
    "        sim_scores = weak_attack_matrix[i]\n",
    "        sim_scores2 = hop_weak_matrix[i]\n",
    "        # Get the indices of the 5 most similar and 5 least similar nodes\n",
    "        top5_sim_indices = np.argsort(sim_scores)[-attack_per_cwe:]  # Most similar\n",
    "        bottom5_sim_indices = np.argsort(sim_scores2)[:attack_per_cwe]  # Least similar\n",
    "        \n",
    "        # Select the most similar positive nodes\n",
    "        # Select the least similar negative nodes\n",
    "        for j in range(len(top5_sim_indices)):\n",
    "            idx1 = top5_sim_indices[j]\n",
    "            idx2 = bottom5_sim_indices[j]\n",
    "            anchor_pos_neg_triple.append((weak_node, attack_nodes[idx1], weakness_nodes[idx2]))\n",
    "    anchor_set = set()\n",
    "    positive_set=set()\n",
    "    negative_set=set()\n",
    "    for a,p,n in anchor_pos_neg_triple:\n",
    "        anchor_set.add(a)\n",
    "        positive_set.add(p)\n",
    "        negative_set.add(n)\n",
    "        if(a>=weak_range[1] or p>=weak_range[1] or n>=weak_range[1]):\n",
    "            print(a,\" \",p,\" \", n)\n",
    "    print(\"# anchor nodes:\",len(anchor_set))\n",
    "    print(\"# postive nodes:\",len(positive_set))\n",
    "    print(\"# negative nodes :\",len(negative_set))\n",
    "    print(\"# examples: \", len(anchor_pos_neg_triple))\n",
    "    with open(output_dir+'anchor_pos_neg_triple_3.pkl', 'wb') as f:\n",
    "        pickle.dump(anchor_pos_neg_triple, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c920c8b1-9427-4bbc-b2cb-5458280ad668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_sample_1()\n",
    "# get_sample_2()\n",
    "# get_sample_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be9afc6-556f-4308-8412-31701c847c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach4: using top and bottom similar for each weak and attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28c15dc-ed3a-4e84-aaa7-e6dd0c62834c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_4():\n",
    "    anchor_pos_neg_triple = []\n",
    "    for i, attack_node in enumerate(attack_nodes):\n",
    "        # Get the similarity scores for the current attack node\n",
    "        sim_scores = attack_weak_matrix[i]\n",
    "        \n",
    "        # Get the indices of the 5 most similar and 5 least similar nodes\n",
    "        top5_sim_indices = np.argsort(sim_scores)[-cwe_per_attack:]  # Most similar\n",
    "        bottom5_sim_indices = np.argsort(sim_scores)[:cwe_per_attack*2]  # Least similar\n",
    "        neg_nodes = []\n",
    "        for i in range(0,len(bottom5_sim_indices),2):\n",
    "            neg_nodes.append([bottom5_sim_indices[i],bottom5_sim_indices[i+1]])\n",
    "        # Select the most similar positive nodes\n",
    "        # Select the least similar negative nodes\n",
    "        for j in range(len(top5_sim_indices)):\n",
    "            idx1 = top5_sim_indices[j]\n",
    "            idx2 = bottom5_sim_indices[j]\n",
    "            anchor_pos_neg_triple.append((attack_node, weakness_nodes[idx1], neg_nodes[j]))\n",
    "    for i, weak_node in enumerate(weakness_nodes):\n",
    "        # Get the similarity scores for the current attack node\n",
    "        sim_scores = weak_attack_matrix[i]\n",
    "        \n",
    "        # Get the indices of the 5 most similar and 5 least similar nodes\n",
    "        top5_sim_indices = np.argsort(sim_scores)[-attack_per_cwe:]  # Most similar\n",
    "        bottom5_sim_indices = np.argsort(sim_scores)[:attack_per_cwe*2]  # Least similar\n",
    "        neg_nodes = []\n",
    "        for i in range(0,len(bottom5_sim_indices),2):\n",
    "            neg_nodes.append([bottom5_sim_indices[i],bottom5_sim_indices[i+1]])\n",
    "        # Select the most similar positive nodes\n",
    "        # Select the least similar negative nodes\n",
    "        print(len(neg_nodes))\n",
    "        print(len(top5_sim_indices))\n",
    "        for j in range(len(top5_sim_indices)):\n",
    "            idx1 = top5_sim_indices[j]\n",
    "            idx2 = bottom5_sim_indices[j]\n",
    "            anchor_pos_neg_triple.append((weak_node, attack_nodes[idx1], neg_nodes[j]))\n",
    "    # anchor_set = set()\n",
    "    # positive_set=set()\n",
    "    # negative_set=set()\n",
    "    # for a,p,n in anchor_pos_neg_triple:\n",
    "    #     anchor_set.add(a)\n",
    "    #     positive_set.add(p)\n",
    "    #     negative_set.add(n)\n",
    "    #     if(a>=weak_range[1] or p>=weak_range[1] or n>=weak_range[1]):\n",
    "    #         print(a,\" \",p,\" \", n)\n",
    "    # print(\"# anchor nodes:\",len(anchor_set))\n",
    "    # print(\"# postive nodes:\",len(positive_set))\n",
    "    # print(\"# negative nodes :\",len(negative_set))\n",
    "    # print(\"# examples: \", len(anchor_pos_neg_triple))\n",
    "    with open(output_dir+'anchor_pos_neg_triple_4.pkl', 'wb') as f:\n",
    "        pickle.dump(anchor_pos_neg_triple, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f550efd-2eb3-4c99-8dd0-8cfca493bbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_5():\n",
    "    anchor_pos_neg_triple = []\n",
    "    for i, attack_node in enumerate(attack_nodes):\n",
    "        # Get the similarity scores for the current attack node\n",
    "        sim_scores = attack_weak_matrix[i]\n",
    "        \n",
    "        # Get the indices of the 5 most similar and 5 least similar nodes\n",
    "        top5_sim_indices = np.argsort(sim_scores)[-cwe_per_attack:]  # Most similar\n",
    "        bottom5_sim_indices = np.argsort(sim_scores)[:cwe_per_attack]  # Least similar\n",
    "        \n",
    "        # Select the most similar positive nodes\n",
    "        # Select the least similar negative nodes\n",
    "        for j in range(len(top5_sim_indices)):\n",
    "            for k in range(len(bottom5_sim_indices)):\n",
    "                idx1 = top5_sim_indices[j]\n",
    "                idx2 = bottom5_sim_indices[k]\n",
    "                anchor_pos_neg_triple.append((attack_node, weakness_nodes[idx1], weakness_nodes[idx2]))\n",
    "    for i, weak_node in enumerate(weakness_nodes):\n",
    "        # Get the similarity scores for the current attack node\n",
    "        sim_scores = weak_attack_matrix[i]\n",
    "        \n",
    "        # Get the indices of the 5 most similar and 5 least similar nodes\n",
    "        top5_sim_indices = np.argsort(sim_scores)[-attack_per_cwe:]  # Most similar\n",
    "        bottom5_sim_indices = np.argsort(sim_scores)[:attack_per_cwe]  # Least similar\n",
    "        \n",
    "        # Select the most similar positive nodes\n",
    "        # Select the least similar negative nodes\n",
    "        for j in range(len(top5_sim_indices)):\n",
    "            for k in range(len(bottom5_sim_indices)):\n",
    "                idx1 = top5_sim_indices[j]\n",
    "                idx2 = bottom5_sim_indices[k]\n",
    "                anchor_pos_neg_triple.append((weak_node, attack_nodes[idx1], attack_nodes[idx2]))\n",
    "    anchor_set = set()\n",
    "    positive_set=set()\n",
    "    negative_set=set()\n",
    "    for a,p,n in anchor_pos_neg_triple:\n",
    "        anchor_set.add(a)\n",
    "        positive_set.add(p)\n",
    "        negative_set.add(n)\n",
    "        if(a>=weak_range[1] or p>=weak_range[1] or n>=weak_range[1]):\n",
    "            print(a,\" \",p,\" \", n)\n",
    "    print(\"# anchor nodes:\",len(anchor_set))\n",
    "    print(\"# postive nodes:\",len(positive_set))\n",
    "    print(\"# negative nodes :\",len(negative_set))\n",
    "    print(\"# examples: \", len(anchor_pos_neg_triple))\n",
    "    with open(output_dir+'anchor_pos_neg_triple_5.pkl', 'wb') as f:\n",
    "        pickle.dump(anchor_pos_neg_triple, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63294c9-7384-4e24-a99c-d9a526326850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_sample_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd10f83-f3fd-47fb-8834-8f5c19ec6c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_sample_5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec39a83-f0ca-40d0-bf61-717557138822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach2: using thresold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a39330e-e24b-4f8c-8fe0-93370aaa677c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3]\n",
    "b = a*4\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c74261-63ee-48fd-bb2c-28ca567a1fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81e636a-358e-4563-b983-653e04fd5a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_pos_neg_triple = get_sample_10(text_weak_attack_matrix,text_attack_weak_matrix, sample_no=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0455990-f3bc-4303-b794-4186a6e53ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_pos_neg_triple[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87b6b8e-d8d7-46d4-93b9-d4d16764c256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# from collections import defaultdict\n",
    "# anchor_pos_pair = []\n",
    "# anchor_neg_pair = []\n",
    "# positive_threshold = 0.70\n",
    "# negative_threshold = 0.40\n",
    "# # There are two group of nodes.\n",
    "# # The first 2043 nodes are attack node and the embeddings = (2043, 1600) \n",
    "# # The second set 939 nodes are weakness node and the embedding shape = (939, 1600)\n",
    "# # attack_embeddings.shape = (2043, 1600)\n",
    "# # weakness_embeddings.shape = (939, 1600)\n",
    "\n",
    "# # Compute cosine similarity between weakness and attack nodes\n",
    "# # I calculate weak_attack_matrix a cosine similarity of shape (939,2043) where rows are weakness and columns are attack and values are cosine similarity\n",
    "# weak_attack_matrix = cosine_similarity(weakness_embeddings, attack_embeddings)\n",
    "# # Compute cosine similarity between attack and weakness nodes\n",
    "# # Then I calculate attack_weak_matrix a cosine similarity of shape (2043,939) where rows are attack and columns are weakness and values are cosine similarity\n",
    "# attack_weak_matrix = cosine_similarity(attack_embeddings, weakness_embeddings)\n",
    "# # This loop find the anchor-positive pairs based on positive_threshold and anchor-negative pairs based on negative_threshold from the attack_weak_matrix \n",
    "# for i, attack_node in enumerate(attack_nodes):\n",
    "#     for j, weakness_node in enumerate(weakness_nodes):\n",
    "#         if attack_weak_matrix[i, j] >= positive_threshold:\n",
    "#             anchor_pos_pair.append((attack_node,weakness_node, attack_weak_matrix[i, j]))\n",
    "#         if attack_weak_matrix[i, j] <= negative_threshold:\n",
    "#             anchor_neg_pair.append((attack_node,weakness_node, attack_weak_matrix[i, j]))\n",
    "\n",
    "# # This loop find the anchor-positive pairs based on positive_threshold and anchor-negative pairs based on negative_threshold from the weak_attack_matrix         \n",
    "# for i, weakness_node in enumerate(weakness_nodes):\n",
    "#     for j, attack_node in enumerate(attack_nodes):\n",
    "#         if weak_attack_matrix[i, j] >= positive_threshold:\n",
    "#             anchor_pos_pair.append((weakness_node,attack_node, weak_attack_matrix[i, j]))\n",
    "#         if weak_attack_matrix[i, j] <= negative_threshold:\n",
    "#             anchor_neg_pair.append((weakness_node,attack_node, weak_attack_matrix[i, j]))\n",
    "# # Now I sort the positive pairs in descending order and negative pairs in ascending order\n",
    "# anchor_pos_pair.sort(reverse=True, key=lambda x:x[2])\n",
    "# anchor_neg_pair.sort(key=lambda x:x[2])\n",
    "# print(len(anchor_pos_pair))\n",
    "# print(len(anchor_neg_pair))\n",
    "\n",
    "# Now the main purpose of the code is to make triplet (anchor,positive,negative) from the positive and negative pairs in a way that\n",
    "# For each anchor we choose the highest similar positive node and for the (anchor,positive) pair choose the lowest similar (dissimilar) negative node from (anchor,negative) pairs.\n",
    "# Once i choose a (anchor,positive,negative), i don't want to repeat the negative node for same anchor, so I remove those negative for the next (anchor,positive) pair\n",
    "# This part of the code is taking so much time due to the pop action.\n",
    "\n",
    "# anchor_pos_neg_triple = []\n",
    "# anchor_for_neg = [pair[0] for pair in anchor_neg_pair]\n",
    "# pos_pair = []\n",
    "# neg_pair = []\n",
    "# for anchor,pos,val in anchor_pos_pair:\n",
    "#     if(anchor in anchor_for_neg):\n",
    "#         idx = anchor_for_neg.index(anchor)\n",
    "#         anchor_pos_neg_triple.append((anchor,pos,anchor_neg_pair[idx][1]))\n",
    "#         pos_pair.append((pos,val))\n",
    "#         neg_pair.append((anchor_neg_pair[idx][1],anchor_neg_pair[idx][2]))\n",
    "#         anchor_for_neg.pop(idx)\n",
    "#         anchor_neg_pair.pop(idx)\n",
    "\n",
    "\n",
    "\n",
    "# anchor_dict = defaultdict(list)\n",
    "# anchor_pos_neg_triple = []\n",
    "# pos_pair = []\n",
    "# neg_pair = []\n",
    "# for anchor,neg,val in anchor_neg_pair:\n",
    "#     anchor_dict[anchor].append((anchor,neg,val))\n",
    "# for anchor,pos,val in anchor_pos_pair:\n",
    "#     if(anchor in anchor_dict.keys()):\n",
    "#         idx = random.randrange(0, len(anchor_dict[anchor]))\n",
    "#         anchor_pos_neg_triple.append((anchor,pos,anchor_dict[anchor][idx][1]))\n",
    "#         pos_pair.append((pos,val))\n",
    "#         neg_pair.append((anchor_dict[anchor][idx][1],anchor_dict[anchor][idx][2]))\n",
    "#         #anchor_dict[anchor].pop(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0ddb12-7f75-43ff-8167-456cb53d0995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir2 = '../data1/node_similarities/'+current_model\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.colors as mcolors\n",
    "# def histogram2(all_pairs):\n",
    "#     # print(len(cosine_sim_pairs))\n",
    "#     # print(len(cosine_sim_pairs[0]))\n",
    "#     # for row in cosine_sim_pairs:\n",
    "#     #     print(row[0][1], row[1][1])\n",
    "#     #Extract the cosine similarity values from the filtered results\n",
    "#     #cosine_sim_values = [pair[1] for row in cosine_sim_pairs for pair in row[-30:]]\n",
    "#     cosine_sim_values = [pair[1] for pair in all_pairs]\n",
    "    \n",
    "#     # Define the bins for the histogram\n",
    "#     bins = np.arange(0, 1.1, 0.1)  # Bins from 0 to 1 with step size 0.1\n",
    "    \n",
    "#     # Create the histogram\n",
    "#     plt.hist(cosine_sim_values, bins=bins, edgecolor='black')\n",
    "    \n",
    "#     # Set the x-axis and y-axis labels\n",
    "#     plt.xlabel('Cosine Similarity')\n",
    "#     plt.ylabel('Frequency')\n",
    "    \n",
    "#     # Set the title of the histogram\n",
    "#     plt.title('Attack & Weak Positive')\n",
    "#     plt.savefig(dir2+'/histogram_pos_t_40.png',dpi=300)\n",
    "#     # Show the plot\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e819b0e-9a29-457d-a202-9ef32f650d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram2(pos_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a26753f-5036-463f-9e5c-45bd1c59858a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram2(neg_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018b826b-37d6-4e54-94e6-3754a31c5fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('../data/pos_neg_sample/anchor_pos_neg_triple_4.pkl', 'wb') as f:\n",
    "#     pickle.dump(anchor_pos_neg_triple, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5bcf0d-fbee-4eb6-b3cb-565dccf9ea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/pos_neg_sample/anchor_pos_neg_triple_1.pkl', 'rb') as f:\n",
    "#     x=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e445560f-c681-4d35-85ca-c81de030b45a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab2adb3-4a5e-438b-bbaa-f9a4f569a21e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
