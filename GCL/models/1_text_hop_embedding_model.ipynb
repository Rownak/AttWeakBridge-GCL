{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b323a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7971496-9631-459a-9d7d-0eb074f7a6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" \n",
    "# Check if a GPU is available and if not, use a CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aa5a661-feac-4914-8eb7-0d9d5add8c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dir = \"../../model_outputs/ics_attack/embeddings/\"\n",
    "models = [\"pt_gpt2-xl\",\"gpt2-xl/Epoch_5\",\"gpt2-xl/epoch_10\"]\n",
    "data_dir = \"../../datasets/ics_attack/\"\n",
    "text_emb_dir = embeddings_dir+models[2]+\"/\"\n",
    "\n",
    "\n",
    "with open(data_dir+'doc_id_to_emb_id.json') as f:\n",
    "    doc_id_to_emb_id = json.load(f)\n",
    "with open(data_dir+'emb_id_to_doc_id.json') as f:\n",
    "    emb_id_to_doc_id = json.load(f)\n",
    "\n",
    "training_data = np.load(data_dir+'hop_training_data.npy') # load\n",
    "text_embeddings = np.load(text_emb_dir+'text_embeddings.npy')\n",
    "weights = [x for _,_,x in training_data]\n",
    "pairs = [[int(x),int(y)] for x,y,_ in training_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eebca113-6c4e-4897-89e1-f9a8e8e83b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "455281"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_set = []\n",
    "obj_set2=[]\n",
    "for p1,p2 in pairs:\n",
    "    obj_set.append(p1)\n",
    "    obj_set2.append(p2)\n",
    "len(obj_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ad1a2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455281,)\n",
      "X_training shape: (455281,)\n",
      "Y_training shape: (455281,)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "def shuffle_two_arrays(array1, array2):\n",
    "    combined = list(zip(array1, array2))\n",
    "    random.shuffle(combined)\n",
    "    shuffled_array1, shuffled_array2 = zip(*combined)\n",
    "    return list(shuffled_array1), list(shuffled_array2)\n",
    "spairs, sweights = shuffle_two_arrays(pairs, weights)\n",
    "# Pull out columns for X (data to train with) and Y (value to predict)\n",
    "import numpy as np\n",
    "X_training = np.array(spairs)\n",
    "Y_training = np.array(sweights)\n",
    "Y_training = Y_training.reshape(-1,1)\n",
    "Y_training = Y_training.squeeze()\n",
    "print(Y_training.shape)\n",
    "\n",
    "X1_training = X_training.T[0]\n",
    "X2_training = X_training.T[1]\n",
    "print(\"X_training shape:\",X1_training.shape)\n",
    "print(\"Y_training shape:\",Y_training.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb6fc0e3-8346-4338-9675-f3875f2792cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_OBJECTS = len(doc_id_to_emb_id)\n",
    "EMBEDDING_DIM_1 = len(text_embeddings[0])\n",
    "HIDDEN_DIM = 256\n",
    "EMBEDDING_DIM_2 = 64\n",
    "RUN_NAME = \"run 1 with 200 epoches\"\n",
    "training_epochs = 200\n",
    "learning_rate = 0.001\n",
    "SCALE_FACTOR = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "922fc58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        # Embedding layers\n",
    "        self.text_embedding_layer = nn.Embedding.from_pretrained(torch.FloatTensor(text_embeddings), freeze=True)\n",
    "        self.hidden_layers = nn.Sequential(\n",
    "            nn.Linear(EMBEDDING_DIM_1, HIDDEN_DIM),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HIDDEN_DIM, EMBEDDING_DIM_2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, X1, X2):\n",
    "        # Get embeddings\n",
    "        obj1_text_embedding = self.text_embedding_layer(X1)\n",
    "        obj2_text_embedding = self.text_embedding_layer(X2)\n",
    "        \n",
    "        # Pass embeddings through hidden layers\n",
    "        hidden_output = self.hidden_layers(self.text_embedding_layer.weight)\n",
    "        \n",
    "        # Gather the corresponding embeddings\n",
    "        obj1_model1_embedding = hidden_output[X1]\n",
    "        obj2_model1_embedding = hidden_output[X2]\n",
    "\n",
    "        obj1_model1_embedding_norm = F.normalize(obj1_model1_embedding, p=2, dim=1)\n",
    "        obj2_model1_embedding_norm = F.normalize(obj2_model1_embedding, p=2, dim=1)\n",
    "        obj1_text_embedding_norm = F.normalize(obj1_text_embedding, p=2, dim=1)\n",
    "        obj2_text_embedding_norm = F.normalize(obj2_text_embedding, p=2, dim=1)\n",
    "        \n",
    "        # Compute cosine distances\n",
    "        cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "        hop_dist_predict = SCALE_FACTOR * (1 - cos(obj1_model1_embedding_norm, obj2_model1_embedding_norm))\n",
    "        text_dist_predict = SCALE_FACTOR * (1 - cos(obj1_text_embedding_norm, obj2_text_embedding_norm))\n",
    "        \n",
    "        return hop_dist_predict, text_dist_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70038289-8f74-42f9-98a7-706102a50cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = NeuralNetwork()\n",
    "model = model.to(device)\n",
    "# Define the loss functions\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ccbf1bc1-bf58-44d4-b7b4-b3668054a656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X1_training, X2_training, and Y_training are numpy arrays\n",
    "X1 = torch.tensor(X1_training, dtype=torch.long)\n",
    "X2 = torch.tensor(X2_training, dtype=torch.long)\n",
    "Y = torch.tensor(Y_training, dtype=torch.float32)\n",
    "X1 = X1.to(device)\n",
    "X2 = X2.to(device)\n",
    "Y = Y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c3d038c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 - Training Cost: 35812.890625\n",
      "Epoch: 20 - Training Cost: 7921.5458984375\n",
      "Epoch: 40 - Training Cost: 6284.50341796875\n",
      "Epoch: 60 - Training Cost: 5597.91796875\n",
      "Epoch: 80 - Training Cost: 5192.03173828125\n",
      "Epoch: 100 - Training Cost: 4921.77783203125\n",
      "Epoch: 120 - Training Cost: 4996.1162109375\n",
      "Epoch: 140 - Training Cost: 4630.00341796875\n",
      "Epoch: 160 - Training Cost: 4500.91650390625\n",
      "Epoch: 180 - Training Cost: 4470.48193359375\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "for epoch in range(training_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    hop_dist_predict, text_dist_predict = model(X1, X2)\n",
    "    \n",
    "    loss1 = criterion(Y, hop_dist_predict)\n",
    "    loss2 = criterion(hop_dist_predict, text_dist_predict)\n",
    "    alpha = 0.5\n",
    "    cost = (alpha)*loss1 + (1-alpha)*loss2\n",
    "    \n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 20 == 0:\n",
    "        print(\"Epoch: {} - Training Cost: {}\".format(epoch, cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e1905d9-b2a7-43cf-82bf-a8c84a77644f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save in  ../model_outputs/ics_attack/llm_finetuned_models/gpt2-xl/Epoch_10/text_hop_embeddings.npy\n"
     ]
    }
   ],
   "source": [
    "# Save the embeddings\n",
    "embeddings1_val = model.cpu().text_embedding_layer.weight.data.numpy()\n",
    "embeddings2_val = model.cpu().hidden_layers(model.text_embedding_layer.weight).detach().numpy()\n",
    "text_hop_embeddings = np.array(embeddings2_val, dtype=\"float64\")\n",
    "print(\"save in \", text_emb_dir+\"text_hop_embeddings.npy\")\n",
    "np.save(text_emb_dir+\"text_hop_embeddings.npy\", np.array(embeddings2_val), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce3d5a4-04e3-4ef2-8bf3-0a4632c8b1cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eecb404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# def cos_sim(embeddings_val):\n",
    "#     # Compute cosine similarity between all pairs of embeddings\n",
    "#     cosine_distances = cosine_similarity(embeddings_val)\n",
    "\n",
    "#     # Print cosine distances\n",
    "#     print(\"Cosine distances between all pairs of embeddings:\")\n",
    "#     for i in range(TOTAL_OBJECTS):\n",
    "#         for j in range(i+1, i+5):\n",
    "#             if(j<TOTAL_OBJECTS):\n",
    "#                 print(f\"Pair ({i}, {j}): {cosine_distances[i][j]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cc43ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cos_sim(embeddings2_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fdc733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# import numpy as np\n",
    "# embedding_size=64\n",
    "# def get_cosine_sim(all_embeddings, file):\n",
    "#     f = open(file, \"a\")\n",
    "    \n",
    "#     knnDict = {}\n",
    "#     all_sim = []\n",
    "#     for i in range(len(all_embeddings)):\n",
    "#         x = np.array(all_embeddings[i]).reshape(1,embedding_size)\n",
    "#         #simList = []\n",
    "#         for j in range(i+1,len(all_embeddings)):\n",
    "#             if(i==j):\n",
    "#                 continue\n",
    "#             y = np.array(all_embeddings[j]).reshape(1,embedding_size)\n",
    "            \n",
    "#             cos_sim = cosine_similarity(x, y)\n",
    "#             #simList.append([all_embeddings[j]['simple_id'], cos_sim])\n",
    "#             all_sim.append(cos_sim[0][0])\n",
    "#     #     y= sorted(simList,key=lambda l:l[1], reverse=True)\n",
    "#     #     objName = all_embeddings[i]['simple_id']\n",
    "#     #     #print('Cosine similarity of *', objName)\n",
    "#     #     f.write(f\"\\n___ Cosine similarity of * {objName}____\\n\")\n",
    "#     #     knnList = []\n",
    "#     #     for i in range(0,10):\n",
    "#     #         #print( y[i][0], ': ',\"%.4f\" % y[i][1][0][0])\n",
    "#     #         f.write(f\"{y[i][0]} : {y[i][1][0][0]}\\n\")\n",
    "#     #         knnList.append(y[i][0]+\" \"+str(round(y[i][1][0][0],4)))\n",
    "#     #     knnDict[objName]=knnList\n",
    "#     # f.close()\n",
    "#     np.save(file, np.array(all_sim, dtype=object), allow_pickle=True)\n",
    "#     #b = np.load('a.npy', allow_pickle=True)\n",
    "#     return all_sim\n",
    "#     #print(\"#####################################\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42a0ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_sim= get_cosine_sim(embeddings2_val, \"embeddings_cos_sim.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91585fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def histogram2(all_sim,file):\n",
    "#     # Plot histogram with 5 bins\n",
    "#     plt.hist(all_sim, bins=20, edgecolor='black')\n",
    "    \n",
    "#     # Add labels and title\n",
    "#     plt.xlabel('Values')\n",
    "#     plt.ylabel('Frequency')\n",
    "#     plt.title('Cosine Similarity Distribution of Generated Embeddings')\n",
    "#     plt.savefig(file, dpi=300)\n",
    "#     # Show plot\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ea6178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram2(all_sim,\"synthetic_embedding_cos_sim_distribution.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
