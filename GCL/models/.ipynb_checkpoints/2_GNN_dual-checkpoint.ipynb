{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3c70e95-0f77-4de1-8607-0bd62d156372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "# Ensure to set the correct CUDA device if multiple GPUs are available\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "# Check if a GPU is available and if not, use a CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "317ce5a0-f552-4b4e-a8ca-588e636a8a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"pretrained_SecBert\", \"SecBert_E5\", \"pretrained_SecureBert\",  \"SecureBert_E5\", \"pt_Gpt2\",\"ft_Gpt2_E5\"]\n",
    "# models = [\"pretrained_SecBert\", \"SecBert\", \"pretrained_SecureBert\",  \"SecureBert\", \"pretrained_Gpt2\",\"Gpt2\"]\n",
    "#models = [\"pretrained_SecBert\",\"pretrained_SecureBert\",\"pretrained_Gpt2\"]\n",
    "current_model = models[5]\n",
    "#gnn_model = \"GAT\"\n",
    "gnn_model = \"GCN\"\n",
    "sample = 4\n",
    "margin1=1.0\n",
    "margin2=1.0\n",
    "\n",
    "dir_name = \"../../ics_cwe/Text_Hop/\"+current_model+\"/\"\n",
    "graph_path = \"../../graph_network/data/\"\n",
    "# Assuming predefined weights are stored in a numpy array named 'predefined_embeddings1_weights'\n",
    "text_embeddings = np.load(dir_name+'data/all_embeddings.npy')\n",
    "#feature_2 = np.load(dir_name+'data/our_embeddings.npy')\n",
    "feature_2 = np.load(graph_path+'graph_features/node2vec.npy')\n",
    "with open('../../ics_cwe/id_to_pos.json') as fp:\n",
    "    id_to_pos = json.load(fp)\n",
    "with open('../../ics_cwe/pos_to_id.json') as fp:\n",
    "    pos_to_id = json.load(fp)\n",
    "\n",
    "with open(graph_path+'combined_nodes.json') as fp:\n",
    "    nodes_json = json.load(fp)\n",
    "# with open(graph_path+'combined_edges.json') as fp:\n",
    "#     edges_json = json.load(fp)\n",
    "# SemiSupervised\n",
    "with open(graph_path+'combined_edges.json') as fp:\n",
    "    edges_json = json.load(fp)\n",
    "\n",
    "with open(dir_name+'data/anchor_pos_neg_hop_{}.pkl'.format(sample), 'rb') as f:\n",
    "    anchor_pos_neg_triple=pickle.load(f)\n",
    "\n",
    "# with open(graph_path+'graph_features/anchor_pos_neg_triple_4_node2vec.npy', 'rb') as f:\n",
    "#     anchor_pos_neg_triple=pickle.load(f)\n",
    "gnn_dir = '../../ics_cwe/{}/sample_{}/{}/'.format(gnn_model,sample,current_model)\n",
    "if not os.path.exists(gnn_dir):\n",
    "    os.makedirs(gnn_dir)\n",
    "out_file = '/text_node2vec_dual_gm_{}.npy'.format(margin1, margin2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e012693-68e7-45c7-9e08-8072d013172c",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_range = (0,203)\n",
    "weak_range = (203,1136)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13390bc8-fd25-4b57-8c7b-cd5cb2adcf89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 689, 279, 18, 195)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_pos_neg_triple[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "784cb0bb-9cb0-4477-bb46-937788f3e91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "879"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unq = set()\n",
    "for a,_,_,_,_ in anchor_pos_neg_triple:\n",
    "    unq.add(a)\n",
    "len(unq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1d66a50-194f-4acd-b361-4ad4af1d398f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194\n",
      "685\n"
     ]
    }
   ],
   "source": [
    "print(len([x for x in list(unq) if x < 203]))\n",
    "print(len([x for x in list(unq) if x >= 203]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6341ee35-09a6-4721-8649-7f9d2e1217f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_nodes = []\n",
    "positive_nodes = []\n",
    "negative_nodes = []\n",
    "hp_nodes = []\n",
    "hn_nodes = []\n",
    "for a,p,n,hp,hn in anchor_pos_neg_triple:\n",
    "    anchor_nodes.append(a)\n",
    "    positive_nodes.append(p)\n",
    "    negative_nodes.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba78ab9a-edf3-4793-988e-fec642ccef6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24332"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(negative_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14466510-4747-4ba1-ad1e-fa5b4182879c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24332"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positive_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55a811ed-abb8-469d-bcbc-a3b836221e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24332"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(anchor_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c299c1f9-c9a3-4113-906a-e13ea3fd4680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert lists to tensors for use in the model\n",
    "# anchor_text_embeddings = torch.tensor(text_embeddings[anchor_nodes], dtype=torch.float).to(device)\n",
    "# positive_text_embeddings = torch.tensor(text_embeddings[positive_nodes], dtype=torch.float).to(device)\n",
    "# negative_text_embeddings = torch.tensor(text_embeddings[negative_nodes], dtype=torch.float).to(device)\n",
    "# hp_text_embeddings = torch.tensor(text_embeddings[hp_nodes], dtype=torch.float).to(device)\n",
    "# hn_text_embeddings = torch.tensor(text_embeddings[hn_nodes], dtype=torch.float).to(device)\n",
    "node_text_embeddings = torch.tensor(text_embeddings, dtype=torch.float).to(device)\n",
    "node_feature_2 = torch.tensor(feature_2, dtype=torch.float).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "305075f3-f509-4085-88ec-28c0c7fafd2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(81, 715, 1096, 187, 180),\n",
       " (84, 215, 681, 88, 129),\n",
       " (1119, 104, 198, 1111, 745),\n",
       " (168, 390, 684, 201, 171),\n",
       " (390, 168, 136, 305, 978)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_pos_neg_triple[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e82907a-2c18-4603-b110-a18b4181f01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_list = list(range(0, weak_range[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cf1fa1b-b339-49ad-9497-771c2553f076",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list = [(int(e[0]), int(e[1])) for e in edges_json]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29647bbe-8b30-4a92-bd6d-65ce2313e25d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2455ee12-2971-4cb4-a8d5-7c5d0eaceafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_edge_index = torch.tensor(edge_list, dtype=torch.long).t().contiguous().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c29366b9-bacc-4944-a07b-76563ed0b93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAT model definition\n",
    "class GAT(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, hid_dim):\n",
    "        super(GAT, self).__init__()\n",
    "        self.gat1 = GATConv(in_channels, hid_dim, heads=8)\n",
    "        self.gat2 = GATConv(hid_dim * 8, out_channels, heads=1)\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.gat2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82484571-07aa-47e6-a792-23bf8d29b6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, hid_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hid_dim)\n",
    "        self.conv2 = GCNConv(hid_dim, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1c7f9fa-ab2f-4c57-8f2a-fe71fd3f388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define tensors \n",
    "# tens_1 = torch.Tensor([[11, 12, 13], [14, 15, 16]]) \n",
    "# tens_2 = torch.Tensor([[17, 18, 19], [20, 21, 22]]) \n",
    "# tens_3 = torch.Tensor([[37, 38, 39], [30, 31, 32]]) \n",
    "# # print first tensors \n",
    "# print(\"tens_1 \\n\", tens_1) \n",
    "  \n",
    "# # print second tensor \n",
    "# print(\"tens_2 \\n\", tens_2) \n",
    "  \n",
    "# # call torch,cat() function \n",
    "# # join tensor in -1 dimension \n",
    "# tens = torch.cat((tens_1, tens_2,tens_3), -1) \n",
    "# print(\"join tensors in the -1 dimension \\n\", tens) \n",
    "  \n",
    "# # join tensor in 0 dimension \n",
    "# tens = torch.cat((tens_1, tens_2,tens_3), dim=1) \n",
    "# print(\"join tensors in the 1 dimension \\n\", tens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d626a9f7-5842-4a54-9d21-8814d5ec3673",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualEncoder(nn.Module):\n",
    "    def __init__(self, graph_model1,graph_model2, text_dim,feature_2_dim, hidden_dim):\n",
    "        super(DualEncoder, self).__init__()\n",
    "        self.graph_model1 = graph_model1\n",
    "        self.graph_model2 = graph_model2\n",
    "        self.fc1 = nn.Linear(text_dim, out_channels)\n",
    "        #self.fc2 = nn.Linear(feature_2_dim, feature_2_dim)\n",
    "        self.fc2 = nn.Linear(2*out_channels+feature_2_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, text_emb,feature_2, graph_features, edge_index):\n",
    "        graph_emb1 = self.graph_model1(graph_features, edge_index)\n",
    "        graph_emb2 = self.graph_model2(feature_2, edge_index)\n",
    "        text_emb = self.fc1(text_emb)\n",
    "        # feature_2 = self.fc2(feature_2)\n",
    "        combined_emb = torch.cat([text_emb, graph_emb1, graph_emb2], dim=1)\n",
    "        combined_emb = self.fc2(combined_emb)\n",
    "        return combined_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0689d29-d296-4ca5-9e0a-1571bcecd686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define contrastive loss\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=.5):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        # Normalize the embeddings to unit vectors\n",
    "        anchor_norm = F.normalize(anchor, p=2, dim=1)\n",
    "        positive_norm = F.normalize(positive, p=2, dim=1)\n",
    "        negative_norm = F.normalize(negative, p=2, dim=1)\n",
    "        # Compute the cosine similarity\n",
    "        cos_sim1 = F.cosine_similarity(anchor_norm, positive_norm, dim=1)\n",
    "        cos_sim2 = F.cosine_similarity(anchor_norm, negative_norm, dim=1)\n",
    "        # Cosine distance is 1 - cosine similarity\n",
    "        pos_dist = 1 - cos_sim1\n",
    "        neg_dist = 1 - cos_sim2\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = torch.relu(pos_dist - neg_dist + self.margin).mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d37d9d-3c27-474f-9714-e7b0c7061269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1800e1e8-535d-44e2-8b57-fd28dfc6054f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(64, 64)\n",
      "  (conv2): GCNConv(64, 64)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# GCN Model\n",
    "in_channels = node_text_embeddings.shape[1]  \n",
    "feature_2_dim = node_feature_2.shape[1]  \n",
    "out_channels = 128\n",
    "hidden_dim = 128\n",
    "text_dim = in_channels  # Text embedding dimension\n",
    "if(gnn_model==\"GCN\"):\n",
    "    graph_model1 = GCN(in_channels=in_channels, out_channels=out_channels, hid_dim=128).to(device)\n",
    "    graph_model2 = GCN(in_channels=feature_2_dim, out_channels=feature_2_dim, hid_dim=feature_2_dim).to(device)\n",
    "else:\n",
    "    graph_model1 = GAT(in_channels=in_channels, out_channels=out_channels, hid_dim=128).to(device)\n",
    "    graph_model2 = GAT(in_channels=feature_2_dim, out_channels=feature_2_dim, hid_dim=feature_2_dim).to(device)\n",
    "print(graph_model2)\n",
    "model = DualEncoder(graph_model1,graph_model2, text_dim=text_dim,feature_2_dim=feature_2_dim, hidden_dim=hidden_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5194b5c0-d760-48ab-97c9-aabae75d6486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function and Optimizer\n",
    "contrastive_loss1 = ContrastiveLoss(margin=margin1).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "#scheduler = StepLR(optimizer, step_size=50, gamma=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb7c3f4f-84ea-4528-9106-084d693d284d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.9214301705360413\n",
      "Epoch 10, Loss: 0.0831502228975296\n",
      "Epoch 20, Loss: 0.060156360268592834\n",
      "Epoch 30, Loss: 0.04526502639055252\n",
      "Epoch 40, Loss: 0.036833591759204865\n",
      "Epoch 50, Loss: 0.03131534531712532\n",
      "Epoch 60, Loss: 0.027542781084775925\n",
      "Epoch 70, Loss: 0.024541370570659637\n",
      "Epoch 80, Loss: 0.022278528660535812\n",
      "Epoch 90, Loss: 0.02049735002219677\n",
      "Epoch 100, Loss: 0.019041260704398155\n",
      "Epoch 110, Loss: 0.01785700023174286\n",
      "Epoch 120, Loss: 0.016880078241229057\n",
      "Epoch 130, Loss: 0.016047609969973564\n",
      "Epoch 140, Loss: 0.015312112867832184\n",
      "Epoch 150, Loss: 0.014691143296658993\n",
      "Epoch 160, Loss: 0.014114088378846645\n",
      "Epoch 170, Loss: 0.013577640056610107\n",
      "Epoch 180, Loss: 0.01316805835813284\n",
      "Epoch 190, Loss: 0.01267700083553791\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    gnn_model = model(node_text_embeddings,node_feature_2,node_text_embeddings, full_edge_index)\n",
    "    anchor_output = gnn_model[anchor_nodes]\n",
    "    positive_output = gnn_model[positive_nodes]\n",
    "    negative_output = gnn_model[negative_nodes]\n",
    "    # hp_output = gnn_model[hp_nodes]\n",
    "    # hn_output = gnn_model[hn_nodes]\n",
    "    loss = contrastive_loss1(anchor_output, positive_output, negative_output)\n",
    "    # loss2 = contrastive_loss1(anchor_output, hp_output, hn_output)\n",
    "    # loss = loss1+0.00*loss2\n",
    "    loss.backward()\n",
    "    #torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    #scheduler.step()\n",
    "    if(epoch%10==0):\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31fb1419-9f8f-4710-b27c-c5729cad4b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1136, 128])\n"
     ]
    }
   ],
   "source": [
    "# Extract embeddings for all nodes\n",
    "# node_text_embeddings = torch.tensor(text_embeddings, dtype=torch.float).to(device)\n",
    "# full_edge_index = torch.tensor(edge_list, dtype=torch.long).t().contiguous().to(device)\n",
    "\n",
    "def extract_embeddings(model, node_embeddings,node_feature_2, edge_index):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(node_embeddings,node_feature_2,node_text_embeddings, edge_index)\n",
    "    return embeddings\n",
    "\n",
    "final_node_embeddings = extract_embeddings(model, node_text_embeddings,node_feature_2, full_edge_index)\n",
    "\n",
    "# Print the final embeddings\n",
    "print(final_node_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76223322-b425-4b3a-905b-727ab690d53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import os\n",
    "# # Assuming node_embeddings is a PyTorch tensor\n",
    "# node_embeddings_np = final_node_embeddings.detach().cpu().numpy()\n",
    "\n",
    "# nn_dir = '../data/GAT_embeddings/'+current_model\n",
    "# if not os.path.exists(nn_dir):\n",
    "#     os.makedirs(nn_dir)\n",
    "# np.save(nn_dir+'/node_embeddings_gm_{}_tm_{}.npy'.format(margin1,margin2), np.array(node_embeddings_np)) # save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1456e151-c552-4f60-8531-06acd72195d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import os\n",
    "# # Assuming node_embeddings is a PyTorch tensor\n",
    "# node_embeddings_np = final_node_embeddings.detach().cpu().numpy()\n",
    "\n",
    "# nn_dir = '../data/sample_{}/GAN_embeddings/'.format(sample)+current_model\n",
    "# if not os.path.exists(nn_dir):\n",
    "#     os.makedirs(nn_dir)\n",
    "# np.save(nn_dir+'/node_embeddings_gm_{}.npy'.format(margin1), np.array(node_embeddings_np)) # save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a88dbaa5-7790-4f76-8f61-29ce7cab03c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming node_embeddings is a PyTorch tensor\n",
    "node_embeddings_np = final_node_embeddings.detach().cpu().numpy()\n",
    "np.save(gnn_dir+out_file, np.array(node_embeddings_np)) # save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37eee52-6626-463f-8790-d2dff03c8bfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5d5e0b-95b3-4de3-aa63-b51cd5bd98c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025917ef-7653-459a-93af-988a8b49ac4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4ca3a7-baab-4d54-8e6e-f39beb09a4e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f464937d-ce8b-4713-899b-8f096b3c30b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
