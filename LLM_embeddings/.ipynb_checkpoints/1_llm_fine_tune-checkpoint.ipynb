{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f3241f1-e6c4-4dd8-b566-b3a1bc059d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, GPT2Tokenizer, GPT2LMHeadModel, DataCollatorForLanguageModeling, DataCollatorWithPadding, TrainingArguments, Trainer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" \n",
    "# Check if a GPU is available and if not, use a CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c4462d5-66e0-4130-9c5a-7c91b3f21de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Nodes with Description:  1136\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_dir = \"../datasets/ics_attack/\"\n",
    "output_dir = \"../model_outputs/ics_attack/llm_finetuned_models/\"\n",
    "models = [\"jackaduma/SecRoBERTa\", \"ehsanaghaei/SecureBERT\", \"gpt2-xl\"]\n",
    "model_names = [\"SecRoBERTa\", \"SecureBERT\", \"gpt2-xl\"]\n",
    "model_id = 0\n",
    "n_epoch = 10\n",
    "if not os.path.exists(output_dir+model_names[model_id]):\n",
    "    os.makedirs(output_dir+model_names[model_id])\n",
    "\n",
    "# load attack and weakness description with ID\n",
    "with open(data_dir+\"doc_id_to_desc.json\") as f:\n",
    "    doc_id_to_desc = json.load(f)\n",
    "print(\"Number of Nodes with Description: \",len(doc_id_to_desc))\n",
    "# text_data is a list containing your text data\n",
    "text_data = []  # Your text items\n",
    "for doc_id in doc_id_to_desc:\n",
    "    text_data.append(doc_id_to_desc[doc_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ea48d4-efdb-462e-b4fc-0150d36a27ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b5b0e4-d15d-4e9c-b0a9-5ad9c62629a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the tokenizer and model based on model_name\n",
    "if \"gpt2\" in model_name:\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(models[model_id])\n",
    "    model = GPT2LMHeadModel.from_pretrained(models[model_id])\n",
    "elif(\"SecRoBERTa\" in model_name):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(models[model_id])\n",
    "    model = AutoModelForMaskedLM.from_pretrained(models[model_id])\n",
    "elif(\"SecureBERT\" in model_name):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(models[model_id])\n",
    "    model = AutoModelForMaskedLM.from_pretrained(models[model_id])\n",
    "model.to(device)\n",
    "model.to(device)\n",
    "# Set padding token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ead7ca3-1507-4645-8644-0a2f4e24a9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate max_length based on the longest text in your dataset\n",
    "#max_length = max([len(tokenizer.encode(text)) for text in text_data])\n",
    "max_length = min(max([len(tokenizer.encode(text)) for text in text_data]), 512)  # Limit to 512 tokens\n",
    "print(\"Max # token in the longest text :\",max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bf3429-c068-450b-bc5a-2472a59df545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset\n",
    "# Custom dataset with chunking\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, tokenizer, texts, max_length):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.examples = []\n",
    "\n",
    "        for text in texts:\n",
    "            tokenized_text = tokenizer.encode(text)\n",
    "            for i in range(0, len(tokenized_text), max_length):\n",
    "                chunk = tokenized_text[i:i + max_length]\n",
    "                self.examples.append(chunk)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        chunk = self.examples[idx]\n",
    "        tokenized_inputs = self.tokenizer.prepare_for_model(\n",
    "            chunk,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        tokenized_inputs[\"labels\"] = tokenized_inputs[\"input_ids\"].clone()\n",
    "        # Move tensors to the device\n",
    "        for key in tokenized_inputs:\n",
    "            tokenized_inputs[key] = tokenized_inputs[key].squeeze(0).to(device)\n",
    "        return tokenized_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a078b8-c6c6-48a3-b06f-5092ffd79720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "dataset = CustomDataset(tokenizer, text_data, max_length)\n",
    "# Create a data collator based on model type\n",
    "if \"gpt2\" in model_name:\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "else:\n",
    "    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True, mlm_probability=0.15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cec43b-5bac-42e2-a8b2-d90846a43c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db6c4b5-20d9-4544-b378-44b9a5d49696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training arguments and Trainer\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=2,  # Reduce batch size\n",
    "    gradient_accumulation_steps=4,  # Accumulate gradients over 4 steps\n",
    "    num_train_epochs=n_epoch,\n",
    "    learning_rate=1e-4,\n",
    "    output_dir=output_dir+model_names[model_id]+'/results',\n",
    "    logging_dir=output_dir+model_names[model_id]+'/logs',\n",
    "    logging_steps=100,\n",
    "    load_best_model_at_end=False,\n",
    "    evaluation_strategy=\"no\",\n",
    "    remove_unused_columns=False,\n",
    "    push_to_hub=False,\n",
    "    save_strategy=\"no\",  # Disable checkpoint saving\n",
    "    fp16=True,  # Use mixed precision training\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    eval_dataset=None,  # You can specify an evaluation dataset here\n",
    "    data_collator=data_collator,  # Add the data collator here\n",
    ")\n",
    "# Clear cache before training\n",
    "torch.cuda.empty_cache()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa1a0f9-e28f-4bc8-9655-a4cacea94f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()\n",
    "model.save_pretrained(output_dir+model_names[model_id]+'/epoch_{}'.format(n_epoch))\n",
    "tokenizer.save_pretrained(output_dir+model_names[model_id]+'/epoch_{}'.format(n_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9befc6dd-ac48-4da9-b6bf-1ea375bd4e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f9eadf-60c0-4d11-9d6a-0e19f8cdf675",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
